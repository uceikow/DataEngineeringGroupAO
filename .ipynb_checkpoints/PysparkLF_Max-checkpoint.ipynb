{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "import pyspark\n",
    "\n",
    "number_cores = int(os.environ['NUM_CPUS'])\n",
    "memory_gb = int(os.environ['AVAILABLE_MEMORY_MB']) // 1024\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setMaster('local[{}]'.format(number_cores))\n",
    "        .set('spark.driver.memory', '{}g'.format(memory_gb))\n",
    ")\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[4] appName=pyspark-shell>\n"
     ]
    }
   ],
   "source": [
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "indian = sqlContext.read.csv(\"/project/Project/DataEngineeringGroupAO/Recipe_dataset/data_indian.csv\",header=True)\n",
    "italian = sqlContext.read.csv(\"/project/Project/DataEngineeringGroupAO/Recipe_dataset/data_italian.csv\",header=True)\n",
    "mexican = sqlContext.read.csv(\"/project/Project/DataEngineeringGroupAO/Recipe_dataset/data_mexican.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label the data\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "indian = indian.withColumn(\"label\",lit(\"indian\"))\n",
    "italian = italian.withColumn(\"label\",lit(\"italian\"))\n",
    "mexican = mexican.withColumn(\"label\",lit(\"mexican\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|               Title|         Description| label|\n",
      "+--------------------+--------------------+------+\n",
      "|  Indian Peanut Stew|This is an easy, ...|indian|\n",
      "|        Roomali Roti|There is no leave...|indian|\n",
      "|Spicy Sweet Potat...|It's important to...|indian|\n",
      "|        Chicken Saag|The classic India...|indian|\n",
      "|Paleo Slow Cooker...|Boneless pork loi...|indian|\n",
      "|Bombay Chicken an...|Chicken parts are...|indian|\n",
      "|Indian Carrots, P...|Potatoes, peas an...|indian|\n",
      "|Wendy's Indian Bu...|This recipe resem...|indian|\n",
      "|    Indian Chickpeas|Garbanzo beans, o...|indian|\n",
      "|Dal Makhani (Indi...|These richly spic...|indian|\n",
      "|               Raita|Chopped tomatoes ...|indian|\n",
      "|Yogurt-Marinated ...|A yogurt-based ma...|indian|\n",
      "|Indian-Spiced Roa...|Spicy roasted chi...|indian|\n",
      "|Cauliflower and T...|Pressed tofu cube...|indian|\n",
      "|Channa Masala (Ch...|This fantastic In...|indian|\n",
      "|Bengali Chicken C...|Thy this deliciou...|indian|\n",
      "|  Indian Sweet Bread|A crisp and sweet...|indian|\n",
      "| Rosy's Palak Paneer|An Indian friend ...|indian|\n",
      "|Roti Bread from I...|This version of t...|indian|\n",
      "|Indian Vegetable ...|Basmati rice enha...|indian|\n",
      "+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine 3 dataset into one\n",
    "\n",
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def unionAll(dfs):\n",
    "    return reduce(DataFrame.unionAll, dfs)\n",
    "\n",
    "dfs = [indian, italian, mexican]\n",
    "recipe = unionAll(dfs)\n",
    "recipe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert it to RDD\n",
    "recipe_rdd = recipe.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Title='Indian Peanut Stew', Description='This is an easy, authentic dish from South Asia that appeals to a wide range of tastes. The…', label='indian'),\n",
       " Row(Title='Roomali Roti', Description='There is no leavening in this simple, tender Indian flatbread of bread flour, oil, salt and…', label='indian'),\n",
       " Row(Title='Spicy Sweet Potato Salad', Description=\"It's important to use good mayonnaise in this recipe, and to let the cooked potatoes chill…\", label='indian'),\n",
       " Row(Title='Chicken Saag', Description='The classic Indian chicken and spinach dish gets richness from sour cream.', label='indian'),\n",
       " Row(Title='Paleo Slow Cooker Pork Loin', Description='Boneless pork loin slowly cooks in a curried fruit sauce until tender and delicious.', label='indian')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages needed for data cleaning\n",
    "\n",
    "from pyspark.sql.functions import udf, regexp_replace, lower, col\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|               Title|         Description| label|\n",
      "+--------------------+--------------------+------+\n",
      "|  indian peanut stew|this is an easy, ...|indian|\n",
      "|        roomali roti|there is no leave...|indian|\n",
      "|spicy sweet potat...|it's important to...|indian|\n",
      "|        chicken saag|the classic india...|indian|\n",
      "|paleo slow cooker...|boneless pork loi...|indian|\n",
      "|bombay chicken an...|chicken parts are...|indian|\n",
      "|indian carrots, p...|potatoes, peas an...|indian|\n",
      "|wendy's indian bu...|this recipe resem...|indian|\n",
      "|    indian chickpeas|garbanzo beans, o...|indian|\n",
      "|dal makhani (indi...|these richly spic...|indian|\n",
      "|               raita|chopped tomatoes ...|indian|\n",
      "|yogurt-marinated ...|a yogurt-based ma...|indian|\n",
      "|indian-spiced roa...|spicy roasted chi...|indian|\n",
      "|cauliflower and t...|pressed tofu cube...|indian|\n",
      "|channa masala (ch...|this fantastic in...|indian|\n",
      "|bengali chicken c...|thy this deliciou...|indian|\n",
      "|  indian sweet bread|a crisp and sweet...|indian|\n",
      "| rosy's palak paneer|an indian friend ...|indian|\n",
      "|roti bread from i...|this version of t...|indian|\n",
      "|indian vegetable ...|basmati rice enha...|indian|\n",
      "+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lowercase\n",
    "\n",
    "recipe = recipe.select(*[lower(col(col_name)).name(col_name) for col_name in recipe.columns])\n",
    "recipe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation and digits\n",
    "\n",
    "recipe_clean = recipe.select(regexp_replace('Title', \"[^a-zA-Z\\\\s]\", \"\").alias('title'), \n",
    "    (regexp_replace('Description', \"[^a-zA-Z\\\\s]\", \"\").alias('des')),'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|               title|                 des| label|\n",
      "+--------------------+--------------------+------+\n",
      "|  indian peanut stew|this is an easy a...|indian|\n",
      "|        roomali roti|there is no leave...|indian|\n",
      "|spicy sweet potat...|its important to ...|indian|\n",
      "|        chicken saag|the classic india...|indian|\n",
      "|paleo slow cooker...|boneless pork loi...|indian|\n",
      "|bombay chicken an...|chicken parts are...|indian|\n",
      "|indian carrots pe...|potatoes peas and...|indian|\n",
      "|wendys indian but...|this recipe resem...|indian|\n",
      "|    indian chickpeas|garbanzo beans on...|indian|\n",
      "|dal makhani india...|these richly spic...|indian|\n",
      "|               raita|chopped tomatoes ...|indian|\n",
      "|yogurtmarinated s...|a yogurtbased mar...|indian|\n",
      "|indianspiced roas...|spicy roasted chi...|indian|\n",
      "|cauliflower and t...|pressed tofu cube...|indian|\n",
      "|channa masala chi...|this fantastic in...|indian|\n",
      "|bengali chicken c...|thy this deliciou...|indian|\n",
      "|  indian sweet bread|a crisp and sweet...|indian|\n",
      "|  rosys palak paneer|an indian friend ...|indian|\n",
      "|roti bread from i...|this version of t...|indian|\n",
      "|indian vegetable ...|basmati rice enha...|indian|\n",
      "+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recipe_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|               title|           des_clean| label|\n",
      "+--------------------+--------------------+------+\n",
      "|  indian peanut stew|[easy, authentic,...|indian|\n",
      "|        roomali roti|[leavening, simpl...|indian|\n",
      "|spicy sweet potat...|[important, use, ...|indian|\n",
      "|        chicken saag|[classic, indian,...|indian|\n",
      "|paleo slow cooker...|[boneless, pork, ...|indian|\n",
      "|bombay chicken an...|[chicken, parts, ...|indian|\n",
      "|indian carrots pe...|[potatoes, peas, ...|indian|\n",
      "|wendys indian but...|[recipe, resemble...|indian|\n",
      "|    indian chickpeas|[garbanzo, beans,...|indian|\n",
      "|dal makhani india...|[richly, spiced, ...|indian|\n",
      "|               raita|[chopped, tomatoe...|indian|\n",
      "|yogurtmarinated s...|[yogurtbased, mar...|indian|\n",
      "|indianspiced roas...|[spicy, roasted, ...|indian|\n",
      "|cauliflower and t...|[pressed, tofu, c...|indian|\n",
      "|channa masala chi...|[fantastic, india...|indian|\n",
      "|bengali chicken c...|[thy, delicious, ...|indian|\n",
      "|  indian sweet bread|[crisp, sweet, fl...|indian|\n",
      "|  rosys palak paneer|[indian, friend, ...|indian|\n",
      "|roti bread from i...|[version, delicat...|indian|\n",
      "|indian vegetable ...|[basmati, rice, e...|indian|\n",
      "+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove Stopwords\n",
    "\n",
    "# Tokenize text\n",
    "tokenizer = Tokenizer(inputCol=\"des\", outputCol=\"des_token\")\n",
    "recipe = tokenizer.transform(recipe_clean).select('title','des','des_token','label')\n",
    "# tokenized.select(\"Description\", \"Des_words\")\\\n",
    "    #.withColumn(\"tokens\", countTokens(col(\"Des_words\"))).show(truncate=False)\n",
    "\n",
    "# Remove stopwords\n",
    "remover = StopWordsRemover(inputCol='des_token', outputCol='des_clean')\n",
    "recipe_no_stopw = remover.transform(recipe).select('title','des_clean', 'label')\n",
    "recipe_no_stopw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe = recipe_no_stopw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 3)\n"
     ]
    }
   ],
   "source": [
    "# Filter out different recipes\n",
    "# Create temp table\n",
    "recipe.createOrReplaceTempView('recipes')\n",
    "\n",
    "recipe_ind = sqlContext.sql(\"SELECT * FROM recipes WHERE label == 'indian'\")\n",
    "recipe_ita = sqlContext.sql(\"SELECT * FROM recipes WHERE label == 'italian'\")\n",
    "recipe_mex = sqlContext.sql(\"SELECT * FROM recipes WHERE label == 'mexican'\")\n",
    "# print((recipe_ind.count(), len(recipe_ind.columns)))\n",
    "# print((recipe_ita.count(), len(recipe_ita.columns)))\n",
    "# print((recipe_mex.count(), len(recipe_mex.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We asssume that we do not know labels for the majority of data points, \n",
    "# hence further explore only test split\n",
    "recipe_ind_tr, recipe_ind_ts, recipe_ind_dv = recipe_ind.randomSplit([0.8,0.2,0.1],seed = 11)\n",
    "recipe_ita_tr, recipe_ita_ts, recipe_ita_dv = recipe_ita.randomSplit([0.7,0.2,0.1],seed = 11)\n",
    "recipe_mex_tr, recipe_mex_ts, recipe_mex_dv = recipe_mex.randomSplit([0.7,0.2,0.1],seed = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We left aside dev/val split as 10% of each of the datasets and 20% as test split to calculate accuracies of LFs. Bigger test set of \"gold\" is valuable to get more matches of LFs and see overall performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create frequency list\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "top_n = 15\n",
    "\n",
    "ind_counts = recipe_ind_dv.select(f.explode('des_clean').alias('col')).groupBy('col').count()\n",
    "ind_des_freq = ind_counts.orderBy(ind_counts[\"count\"].desc()).limit(top_n)\n",
    "\n",
    "ita_counts = recipe_ita_dv.select(f.explode('des_clean').alias('col')).groupBy('col').count()\n",
    "ita_des_freq = ita_counts.orderBy(ita_counts[\"count\"].desc()).limit(top_n)\n",
    "\n",
    "mex_counts = recipe_mex_dv.select(f.explode('des_clean').alias('col')).groupBy('col').count()\n",
    "mex_des_freq = mex_counts.orderBy(mex_counts[\"count\"].desc()).limit(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+---------+-----+---------+-----+\n",
      "|        col|count|      col|count|      col|count|\n",
      "+-----------+-----+---------+-----+---------+-----+\n",
      "|     indian|   12|   cheese|    8|  chicken|   12|\n",
      "|      curry|   12|  chicken|    8|  mexican|   11|\n",
      "|    chicken|    8|    sauce|    7|     beef|    9|\n",
      "|     yogurt|    5|     easy|    7|     make|    9|\n",
      "|      sweet|    5|  italian|    6|tortillas|    8|\n",
      "|       rice|    5|   recipe|    5|     rice|    8|\n",
      "|       dish|    4|delicious|    5| tomatoes|    7|\n",
      "|cauliflower|    4|   tomato|    4|   filled|    7|\n",
      "| vegetarian|    4|    using|    3|   recipe|    7|\n",
      "|     spiced|    4|   creamy|    3|    spicy|    7|\n",
      "|       make|    4| parmesan|    3|    beans|    7|\n",
      "|      cumin|    4|    basil|    3|    flour|    6|\n",
      "|      quick|    4|   flavor|    3|     dish|    6|\n",
      "|    mixture|    4|  breasts|    3|    great|    6|\n",
      "|      sauce|    3|   simple|    3|    sauce|    6|\n",
      "+-----------+-----+---------+-----+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View then in one dataframe\n",
    "from pyspark.sql.functions import monotonically_increasing_id \n",
    "\n",
    "df1 = ind_des_freq.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "df2 = ita_des_freq.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "df3 = mex_des_freq.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "\n",
    "des_freq = df1.join(df2,(\"row_id\")).join(df3,(\"row_id\")).drop(\"row_id\")\n",
    "des_freq.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train split full\n",
    "df_tr = recipe_ind_tr.union(recipe_ita_tr)\n",
    "df_tr = df_concat.union(recipe_mex_tr)\n",
    "\n",
    "# test split \n",
    "df_ts = recipe_ind_ts.union(recipe_ita_ts)\n",
    "df_ts = df_ts.union(recipe_mex_ts)\n",
    "# dev/val split\n",
    "df_dv = recipe_ind_dv.union(recipe_ita_dv)\n",
    "df_dv = df_dv.union(recipe_mex_dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(title='ada adai', des_clean=['try', 'crepelike', 'items', 'indianstyle', 'breakfast', 'made', 'lentils', 'rice'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop train split for labelling\n",
    "df_tr.drop('label').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
