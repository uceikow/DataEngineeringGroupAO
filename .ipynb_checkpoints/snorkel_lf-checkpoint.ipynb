{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/uceikow/DataEngineeringGroupAO/blob/master/snorkel_lf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WL0ih9fRhPEh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snorkel\n",
      "  Downloading snorkel-0.9.3-py3-none-any.whl (139 kB)\n",
      "\u001b[K     |████████████████████████████████| 139 kB 11.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm<5.0.0,>=4.33.0\n",
      "  Downloading tqdm-4.43.0-py2.py3-none-any.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 619 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting munkres==1.1.2\n",
      "  Downloading munkres-1.1.2-py2.py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.2.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from snorkel) (1.4.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.16.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from snorkel) (1.18.1)\n",
      "Collecting tensorboardX<2.0,>=1.6\n",
      "  Downloading tensorboardX-1.9-py2.py3-none-any.whl (190 kB)\n",
      "\u001b[K     |████████████████████████████████| 190 kB 14.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn<0.22.0,>=0.20.2\n",
      "  Downloading scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.7 MB 43.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas<0.26.0,>=0.25.0\n",
      "  Downloading pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.4 MB 34.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch<1.2.0,>=1.1.0\n",
      "  Downloading torch-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (676.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 676.9 MB 2.9 kB/s  eta 0:00:011�██ | 654.9 MB 31.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting networkx<2.4,>=2.2\n",
      "  Downloading networkx-2.3.zip (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 92.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from tensorboardX<2.0,>=1.6->snorkel) (3.11.3)\n",
      "Requirement already satisfied: six in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from tensorboardX<2.0,>=1.6->snorkel) (1.14.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from scikit-learn<0.22.0,>=0.20.2->snorkel) (0.14.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from pandas<0.26.0,>=0.25.0->snorkel) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from pandas<0.26.0,>=0.25.0->snorkel) (2019.3)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from networkx<2.4,>=2.2->snorkel) (4.4.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from protobuf>=3.8.0->tensorboardX<2.0,>=1.6->snorkel) (45.2.0.post20200210)\n",
      "Building wheels for collected packages: networkx\n",
      "  Building wheel for networkx (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for networkx: filename=networkx-2.3-py2.py3-none-any.whl size=1556408 sha256=cf64761a74de58c1d2731811db203130c99839636e65b4f0a758040c7998d8e3\n",
      "  Stored in directory: /home/faculty/.cache/pip/wheels/81/dc/bb/fbde77ddcbf8d5a04787faf6cc9f1edf4c70a67961d7c75abf\n",
      "Successfully built networkx\n",
      "\u001b[31mERROR: faculty-models 0.1.1 has requirement mlflow-faculty>=0.4.3, but you'll have mlflow-faculty 0.4.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tqdm, munkres, tensorboardX, scikit-learn, pandas, torch, networkx, snorkel\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22.1\n",
      "    Uninstalling scikit-learn-0.22.1:\n",
      "      Successfully uninstalled scikit-learn-0.22.1\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.0.1\n",
      "    Uninstalling pandas-1.0.1:\n",
      "      Successfully uninstalled pandas-1.0.1\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 2.4\n",
      "    Uninstalling networkx-2.4:\n",
      "      Successfully uninstalled networkx-2.4\n",
      "Successfully installed munkres-1.1.2 networkx-2.3 pandas-0.25.3 scikit-learn-0.21.3 snorkel-0.9.3 tensorboardX-1.9 torch-1.1.0 tqdm-4.43.0\n"
     ]
    }
   ],
   "source": [
    "! pip install snorkel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "t1h9pOtvj_51",
    "outputId": "cea01d61-03be-4bd0-e4b2-9638c56cfafc"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'CLOUDSDK_CONFIG'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-70fa3ee281fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# This will prompt for authorization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m   \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m   \u001b[0mhome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[0mroot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_env\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0mhome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HOME'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   root_dir = _os.path.realpath(\n\u001b[0;32m---> 43\u001b[0;31m       _os.path.join(_os.environ['CLOUDSDK_CONFIG'], '../..'))\n\u001b[0m\u001b[1;32m     44\u001b[0m   \u001b[0minet_family\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'IPV4_ONLY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0mdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/dev/fuse'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CLOUDSDK_CONFIG'"
     ]
    }
   ],
   "source": [
    "# Load the Drive helper and mount\n",
    "# !pip install google.colab\n",
    "from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vFG3hE1Mm7HA",
    "outputId": "61826594-4676-499f-8610-1f4012377cc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/My\\ Drive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "colab_type": "code",
    "id": "1TZSIWKjkYiG",
    "outputId": "3882c569-cae4-4ae2-cb4f-9d179f72f7a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (2.4.5)\n",
      "Requirement already satisfied: py4j==0.10.7 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.7)\n",
      "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (2.4.5)\n",
      "Requirement already satisfied: py4j==0.10.7 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.7)\n",
      "Requirement already satisfied: altair in /usr/local/lib/python3.6/dist-packages (4.0.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from altair) (2.11.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from altair) (0.25.3)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from altair) (0.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from altair) (1.17.5)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from altair) (2.6.0)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.6/dist-packages (from altair) (0.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->altair) (1.1.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->altair) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->altair) (2.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->altair) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "# Install spark-related dependencies\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "# !wget -q http://www-eu.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
    "# !tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
    "\n",
    "!pip install -q findspark\n",
    "!pip install pyspark\n",
    "# Set up required environment variables\n",
    "\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/drive/My Drive/spark-2.4.5-bin-hadoop2.7\"\n",
    "!pip install pyspark\n",
    "!pip install altair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RzMzZ5c8hPEn"
   },
   "outputs": [],
   "source": [
    "! pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "id": "PcrYo7xyhPEp",
    "outputId": "a176c5e6-0d61-4668-826a-c9e011f13ddc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "Y9ntcGwAhPE5",
    "outputId": "2b4b9319-bf87-447c-b0b6-4e00d5df64e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[*] appName=pyspark-shell>\n",
      "<pyspark.sql.session.SparkSession object at 0x7faa1bd5beb8>\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "# get a spark context\n",
    "sc = pyspark.SparkContext.getOrCreate()\n",
    "print(sc)\n",
    "\n",
    "# get the context\n",
    "sqlContext = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "print(sqlContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s8NMX7sJBFWa"
   },
   "outputs": [],
   "source": [
    "# Display full output rather than just the last line of output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wVHdxlF4hPFH"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "import pandas as pd\n",
    "\n",
    "PATH = 'https://raw.githubusercontent.com/uceikow/DataEngineeringGroupAO/master/Recipe_dataset/'\n",
    "\n",
    "indian = pd.read_json(PATH + \"data_indian.json\")\n",
    "indian['label'] = 'indian'\n",
    "italian = pd.read_json(PATH + \"data_italian.json\")\n",
    "italian['label'] = 'italian'\n",
    "mexican = pd.read_json(PATH + \"data_mexican.json\")\n",
    "mexican['label'] = 'mexican'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "colab_type": "code",
    "id": "iYDYOIHqqi3z",
    "outputId": "d20da84c-cb5f-48e9-a199-384b58180452"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indian Peanut Stew</td>\n",
       "      <td>This is an easy, authentic dish from South Asi...</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Roomali Roti</td>\n",
       "      <td>There is no leavening in this simple, tender I...</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spicy Sweet Potato Salad</td>\n",
       "      <td>It's important to use good mayonnaise in this ...</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicken Saag</td>\n",
       "      <td>The classic Indian chicken and spinach dish ge...</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paleo Slow Cooker Pork Loin</td>\n",
       "      <td>Boneless pork loin slowly cooks in a curried f...</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>Taco Stew</td>\n",
       "      <td>Ground beef and onions sauteed with a packet o...</td>\n",
       "      <td>mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>Chicken Tortilla Soup in the Slow Cooker</td>\n",
       "      <td>Everyone loves using their slow cooker to make...</td>\n",
       "      <td>mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>Bountiful Garden Zucchini Enchiladas</td>\n",
       "      <td>Fresh zucchini and Monterey Jack cheese filled...</td>\n",
       "      <td>mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>Bean and Honey Burrito Casserole</td>\n",
       "      <td>Here's a great way to feed burritos to a crowd...</td>\n",
       "      <td>mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>Green Chile Chicken Stew</td>\n",
       "      <td>This stew will keep you warm and cozy on those...</td>\n",
       "      <td>mexican</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Title  ...    label\n",
       "0                           Indian Peanut Stew  ...   indian\n",
       "1                                 Roomali Roti  ...   indian\n",
       "2                     Spicy Sweet Potato Salad  ...   indian\n",
       "3                                 Chicken Saag  ...   indian\n",
       "4                  Paleo Slow Cooker Pork Loin  ...   indian\n",
       "...                                        ...  ...      ...\n",
       "1495                                 Taco Stew  ...  mexican\n",
       "1496  Chicken Tortilla Soup in the Slow Cooker  ...  mexican\n",
       "1497      Bountiful Garden Zucchini Enchiladas  ...  mexican\n",
       "1498          Bean and Honey Burrito Casserole  ...  mexican\n",
       "1499                  Green Chile Chicken Stew  ...  mexican\n",
       "\n",
       "[1500 rows x 3 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat them into one dataset\n",
    "recipe = pd.concat([indian, italian, mexican],ignore_index = True)\n",
    "recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "tdbski8thPFQ",
    "outputId": "83732d81-a32c-4f55-d41c-6d54f8765fcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5B5GRAyfhPFS"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "Byvg_0k7hPFU",
    "outputId": "265e81ea-f562-4559-cf93-488213f3540b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fdZMV8XFyXfL"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BsgxdYe9p-TS"
   },
   "outputs": [],
   "source": [
    "# Clean the dataset\n",
    "# Lowercase\n",
    "recipe = recipe.apply(lambda row: row.str.lower())\n",
    "\n",
    "# Remove digits\n",
    "recipe['Title'] = recipe.apply((lambda row: ''.join([i for i in row['Title'] if not i.isdigit()])),axis = 1)\n",
    "recipe['Description'] = recipe.apply((lambda row: ''.join([i for i in row['Description'] if not i.isdigit()])),axis = 1)\n",
    "\n",
    "# Remove punctuations\n",
    "recipe['Title'] = recipe.apply((lambda row: ''.join([i for i in row['Title'] if i not in string.punctuation])),axis=1)\n",
    "recipe['Description'] = recipe.apply((lambda row: ''.join([i for i in row['Description'] if i not in string.punctuation])),axis=1)\n",
    "\n",
    "# Remove Stopwords\n",
    "stop = stopwords.words('english')\n",
    "recipe['Title'] = recipe['Title'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "recipe['Description'] = recipe['Description'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "rPeGEU8Z5dIZ",
    "outputId": "160cab6b-5b0c-4022-a98e-74d282eca748"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indian peanut stew</td>\n",
       "      <td>easy authentic dish south asia appeals wide ra...</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roomali roti</td>\n",
       "      <td>leavening simple tender indian flatbread bread...</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spicy sweet potato salad</td>\n",
       "      <td>important use good mayonnaise recipe let cooke...</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chicken saag</td>\n",
       "      <td>classic indian chicken spinach dish gets richn...</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paleo slow cooker pork loin</td>\n",
       "      <td>boneless pork loin slowly cooks curried fruit ...</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Title  ...   label\n",
       "0           indian peanut stew  ...  indian\n",
       "1                 roomali roti  ...  indian\n",
       "2     spicy sweet potato salad  ...  indian\n",
       "3                 chicken saag  ...  indian\n",
       "4  paleo slow cooker pork loin  ...  indian\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hOFD7g02CwKl"
   },
   "source": [
    "Before splitting the dataset and writing labelling function,  we might want to first get an idea of how our targetting labels look like. This gives us some basic information of how to start building the labelling function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 701
    },
    "colab_type": "code",
    "id": "BgzIrjKY9S9x",
    "outputId": "53f64bd4-685d-4e7a-fb91-775fb02ef590"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All frequencies:\n",
      "============================================================\n",
      "   Word_title  Frequency\n",
      "0     chicken         92\n",
      "1       curry         82\n",
      "2      indian         72\n",
      "3      masala         30\n",
      "4        rice         28\n",
      "5       spicy         25\n",
      "6     curried         21\n",
      "7      paneer         20\n",
      "8     chutney         20\n",
      "9        soup         20\n",
      "10      salad         19\n",
      "11       easy         19\n",
      "12       lamb         17\n",
      "13     tomato         17\n",
      "14     potato         16\n",
      "============================================================\n",
      "All frequencies:\n",
      "============================================================\n",
      "   Word_description  Frequency\n",
      "0            indian        119\n",
      "1             curry        101\n",
      "2              dish         83\n",
      "3           chicken         80\n",
      "4            recipe         61\n",
      "5              rice         53\n",
      "6             spicy         51\n",
      "7            spices         50\n",
      "8              made         48\n",
      "9             sauce         44\n",
      "10             easy         41\n",
      "11         simmered         39\n",
      "12           yogurt         36\n",
      "13         potatoes         35\n",
      "14             make         35\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Patterns from indian food\n",
    "\n",
    "# Filter out indian food\n",
    "recipe_ind = recipe[recipe['label'] == 'indian']\n",
    "\n",
    "# Word frequency in 'Title'\n",
    "top_N = 15\n",
    "titles = recipe_ind.Title.str.cat(sep=' ')\n",
    "words_in_title = nltk.tokenize.word_tokenize(titles)\n",
    "word_dist_title = nltk.FreqDist(words_in_title)\n",
    "print('All frequencies:')\n",
    "print('=' * 60)\n",
    "t_freq = pd.DataFrame(word_dist_title.most_common(top_N),\n",
    "                    columns=['Word_title', 'Frequency'])\n",
    "print(t_freq)\n",
    "print('=' * 60)\n",
    "\n",
    "# Word frequency in 'Description'\n",
    "des = recipe_ind.Description.str.cat(sep=' ')\n",
    "words_in_des = nltk.tokenize.word_tokenize(des)\n",
    "word_dist_des = nltk.FreqDist(words_in_des)\n",
    "print('All frequencies:')\n",
    "print('=' * 60)\n",
    "d_freq = pd.DataFrame(word_dist_des.most_common(top_N),\n",
    "                    columns=['Word_description', 'Frequency'])\n",
    "print(d_freq)\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5EEimMn1BXzs"
   },
   "source": [
    "From the frequency list we could see that some of the words, such as indian, curry, chicken, spicy, spiced, masala, etc,  are frequently showed up in indian recipe. We can include these words into labelling function.\n",
    "\n",
    "Inspection is ongoing. Feel free to explore the indian recipe to get useful information to inform the labelling functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nXbdMtOGEFPi"
   },
   "source": [
    "As being discussed in group meeting, we split the dataset into training, validation, development and test datasets.\n",
    "\n",
    "If we do multi-labelling, we need to make sure that all datasets above contains same proportion of the 3 recipes. I decided to have 30% labelled data, in which 10% for dev set, 10% for validation set, and the remaining 10% for test set. We left 70% data to training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Agcde9nWCooH"
   },
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "# Use ShuffleStratifiedSplit to ensure same proportion of each dataset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=3, test_size=0.3, random_state=0)\n",
    "\n",
    "# Get different labelled data\n",
    "ind = recipe[recipe['label'] == 'indian']\n",
    "ind.reset_index(drop=True,inplace=True)\n",
    "ita = recipe[recipe['label'] == 'italian']\n",
    "ita.reset_index(drop=True,inplace=True)\n",
    "mex = recipe[recipe['label'] == 'mexican']\n",
    "mex.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# Split function (leave 70% for training)\n",
    "def shuffle_split(df,sss):\n",
    "  X = df[['Title','Description']]\n",
    "  y = df['label']\n",
    "  for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "ind_train, ind_test, ind_train, ind_test = shuffle_split(ind,sss)\n",
    "ita_train, ita_test, ita_train, ita_test = shuffle_split(ita,sss)\n",
    "mex_train, mex_test, mex_train, mex_test = shuffle_split(mex,sss)\n",
    "\n",
    "# From randomly sampled test set get dev set and validation set.\n",
    "ind_val, ind_dev = ind_test[:50], ind_test[50:100]\n",
    "ita_val, ita_dev = ita_test[:50], ita_test[50:100]\n",
    "mex_val, mex_dev = mex_test[:50], mex_test[50:100]\n",
    "ind_test, ita_test, mex_test = ind_test[100:150], ita_test[100:150], mex_test[100:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-OxgR17ORUlH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "snorkel_lf.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
