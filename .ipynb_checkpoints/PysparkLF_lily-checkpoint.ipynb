{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "import pyspark\n",
    "\n",
    "number_cores = int(os.environ['NUM_CPUS'])\n",
    "memory_gb = int(os.environ['AVAILABLE_MEMORY_MB']) // 1024\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setMaster('local[{}]'.format(number_cores))\n",
    "        .set('spark.driver.memory', '{}g'.format(memory_gb))\n",
    ")\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[4] appName=pyspark-shell>\n"
     ]
    }
   ],
   "source": [
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "indian = sqlContext.read.csv(\"/project/Project/DataEngineeringGroupAO/Recipe_dataset/data_indian.csv\",header=True)\n",
    "italian = sqlContext.read.csv(\"/project/Project/DataEngineeringGroupAO/Recipe_dataset/data_italian.csv\",header=True)\n",
    "mexican = sqlContext.read.csv(\"/project/Project/DataEngineeringGroupAO/Recipe_dataset/data_mexican.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label the data\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "indian = indian.withColumn(\"label\",lit(\"indian\"))\n",
    "italian = italian.withColumn(\"label\",lit(\"italian\"))\n",
    "mexican = mexican.withColumn(\"label\",lit(\"mexican\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|               Title|         Description| label|\n",
      "+--------------------+--------------------+------+\n",
      "|  Indian Peanut Stew|This is an easy, ...|indian|\n",
      "|        Roomali Roti|There is no leave...|indian|\n",
      "|Spicy Sweet Potat...|It's important to...|indian|\n",
      "|        Chicken Saag|The classic India...|indian|\n",
      "|Paleo Slow Cooker...|Boneless pork loi...|indian|\n",
      "|Bombay Chicken an...|Chicken parts are...|indian|\n",
      "|Indian Carrots, P...|Potatoes, peas an...|indian|\n",
      "|Wendy's Indian Bu...|This recipe resem...|indian|\n",
      "|    Indian Chickpeas|Garbanzo beans, o...|indian|\n",
      "|Dal Makhani (Indi...|These richly spic...|indian|\n",
      "|               Raita|Chopped tomatoes ...|indian|\n",
      "|Yogurt-Marinated ...|A yogurt-based ma...|indian|\n",
      "|Indian-Spiced Roa...|Spicy roasted chi...|indian|\n",
      "|Cauliflower and T...|Pressed tofu cube...|indian|\n",
      "|Channa Masala (Ch...|This fantastic In...|indian|\n",
      "|Bengali Chicken C...|Thy this deliciou...|indian|\n",
      "|  Indian Sweet Bread|A crisp and sweet...|indian|\n",
      "| Rosy's Palak Paneer|An Indian friend ...|indian|\n",
      "|Roti Bread from I...|This version of t...|indian|\n",
      "|Indian Vegetable ...|Basmati rice enha...|indian|\n",
      "+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine 3 dataset into one\n",
    "\n",
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def unionAll(dfs):\n",
    "    return reduce(DataFrame.unionAll, dfs)\n",
    "\n",
    "dfs = [indian, italian, mexican]\n",
    "recipe = unionAll(dfs)\n",
    "recipe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the size of the dataset\n",
    "recipe.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert it to RDD\n",
    "recipe_rdd = recipe.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Title='Indian Peanut Stew', Description='This is an easy, authentic dish from South Asia that appeals to a wide range of tastes. The…', label='indian'),\n",
       " Row(Title='Roomali Roti', Description='There is no leavening in this simple, tender Indian flatbread of bread flour, oil, salt and…', label='indian'),\n",
       " Row(Title='Spicy Sweet Potato Salad', Description=\"It's important to use good mayonnaise in this recipe, and to let the cooked potatoes chill…\", label='indian'),\n",
       " Row(Title='Chicken Saag', Description='The classic Indian chicken and spinach dish gets richness from sour cream.', label='indian'),\n",
       " Row(Title='Paleo Slow Cooker Pork Loin', Description='Boneless pork loin slowly cooks in a curried fruit sauce until tender and delicious.', label='indian')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages needed for data cleaning\n",
    "\n",
    "from pyspark.sql.functions import udf, regexp_replace, lower, col\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|               Title|         Description| label|\n",
      "+--------------------+--------------------+------+\n",
      "|  indian peanut stew|this is an easy, ...|indian|\n",
      "|        roomali roti|there is no leave...|indian|\n",
      "|spicy sweet potat...|it's important to...|indian|\n",
      "|        chicken saag|the classic india...|indian|\n",
      "|paleo slow cooker...|boneless pork loi...|indian|\n",
      "|bombay chicken an...|chicken parts are...|indian|\n",
      "|indian carrots, p...|potatoes, peas an...|indian|\n",
      "|wendy's indian bu...|this recipe resem...|indian|\n",
      "|    indian chickpeas|garbanzo beans, o...|indian|\n",
      "|dal makhani (indi...|these richly spic...|indian|\n",
      "|               raita|chopped tomatoes ...|indian|\n",
      "|yogurt-marinated ...|a yogurt-based ma...|indian|\n",
      "|indian-spiced roa...|spicy roasted chi...|indian|\n",
      "|cauliflower and t...|pressed tofu cube...|indian|\n",
      "|channa masala (ch...|this fantastic in...|indian|\n",
      "|bengali chicken c...|thy this deliciou...|indian|\n",
      "|  indian sweet bread|a crisp and sweet...|indian|\n",
      "| rosy's palak paneer|an indian friend ...|indian|\n",
      "|roti bread from i...|this version of t...|indian|\n",
      "|indian vegetable ...|basmati rice enha...|indian|\n",
      "+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lowercase\n",
    "\n",
    "recipe = recipe.select(*[lower(col(col_name)).name(col_name) for col_name in recipe.columns])\n",
    "recipe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation and digits\n",
    "\n",
    "recipe_clean = recipe.select(regexp_replace('Title', \"[^a-zA-Z\\\\s]\", \"\").alias('title'), \n",
    "    (regexp_replace('Description', \"[^a-zA-Z\\\\s]\", \"\").alias('des')),'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|               title|                 des| label|\n",
      "+--------------------+--------------------+------+\n",
      "|  indian peanut stew|this is an easy a...|indian|\n",
      "|        roomali roti|there is no leave...|indian|\n",
      "|spicy sweet potat...|its important to ...|indian|\n",
      "|        chicken saag|the classic india...|indian|\n",
      "|paleo slow cooker...|boneless pork loi...|indian|\n",
      "|bombay chicken an...|chicken parts are...|indian|\n",
      "|indian carrots pe...|potatoes peas and...|indian|\n",
      "|wendys indian but...|this recipe resem...|indian|\n",
      "|    indian chickpeas|garbanzo beans on...|indian|\n",
      "|dal makhani india...|these richly spic...|indian|\n",
      "|               raita|chopped tomatoes ...|indian|\n",
      "|yogurtmarinated s...|a yogurtbased mar...|indian|\n",
      "|indianspiced roas...|spicy roasted chi...|indian|\n",
      "|cauliflower and t...|pressed tofu cube...|indian|\n",
      "|channa masala chi...|this fantastic in...|indian|\n",
      "|bengali chicken c...|thy this deliciou...|indian|\n",
      "|  indian sweet bread|a crisp and sweet...|indian|\n",
      "|  rosys palak paneer|an indian friend ...|indian|\n",
      "|roti bread from i...|this version of t...|indian|\n",
      "|indian vegetable ...|basmati rice enha...|indian|\n",
      "+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recipe_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|               title|           des_clean| label|\n",
      "+--------------------+--------------------+------+\n",
      "|  indian peanut stew|[easy, authentic,...|indian|\n",
      "|        roomali roti|[leavening, simpl...|indian|\n",
      "|spicy sweet potat...|[important, use, ...|indian|\n",
      "|        chicken saag|[classic, indian,...|indian|\n",
      "|paleo slow cooker...|[boneless, pork, ...|indian|\n",
      "|bombay chicken an...|[chicken, parts, ...|indian|\n",
      "|indian carrots pe...|[potatoes, peas, ...|indian|\n",
      "|wendys indian but...|[recipe, resemble...|indian|\n",
      "|    indian chickpeas|[garbanzo, beans,...|indian|\n",
      "|dal makhani india...|[richly, spiced, ...|indian|\n",
      "|               raita|[chopped, tomatoe...|indian|\n",
      "|yogurtmarinated s...|[yogurtbased, mar...|indian|\n",
      "|indianspiced roas...|[spicy, roasted, ...|indian|\n",
      "|cauliflower and t...|[pressed, tofu, c...|indian|\n",
      "|channa masala chi...|[fantastic, india...|indian|\n",
      "|bengali chicken c...|[thy, delicious, ...|indian|\n",
      "|  indian sweet bread|[crisp, sweet, fl...|indian|\n",
      "|  rosys palak paneer|[indian, friend, ...|indian|\n",
      "|roti bread from i...|[version, delicat...|indian|\n",
      "|indian vegetable ...|[basmati, rice, e...|indian|\n",
      "+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove Stopwords\n",
    "\n",
    "# Tokenize text\n",
    "tokenizer = Tokenizer(inputCol=\"des\", outputCol=\"des_token\")\n",
    "recipe = tokenizer.transform(recipe_clean).select('title','des','des_token','label')\n",
    "# tokenized.select(\"Description\", \"Des_words\")\\\n",
    "    #.withColumn(\"tokens\", countTokens(col(\"Des_words\"))).show(truncate=False)\n",
    "\n",
    "# Remove stopwords\n",
    "remover = StopWordsRemover(inputCol='des_token', outputCol='des_clean')\n",
    "recipe_no_stopw = remover.transform(recipe).select('title','des_clean', 'label')\n",
    "recipe_no_stopw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe = recipe_no_stopw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out different recipes\n",
    "# Create temp table\n",
    "recipe.createOrReplaceTempView('recipes')\n",
    "\n",
    "recipe_ind = sqlContext.sql(\"SELECT * FROM recipes WHERE label == 'indian'\")\n",
    "recipe_ita = sqlContext.sql(\"SELECT * FROM recipes WHERE label == 'italian'\")\n",
    "recipe_mex = sqlContext.sql(\"SELECT * FROM recipes WHERE label == 'mexican'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create frequency list\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "top_n = 15\n",
    "\n",
    "ind_counts = recipe_ind.select(f.explode('des_clean').alias('col')).groupBy('col').count()\n",
    "ind_des_freq = ind_counts.orderBy(ind_counts[\"count\"].desc()).limit(top_n)\n",
    "\n",
    "ita_counts = recipe_ita.select(f.explode('des_clean').alias('col')).groupBy('col').count()\n",
    "ita_des_freq = ita_counts.orderBy(ita_counts[\"count\"].desc()).limit(top_n)\n",
    "\n",
    "mex_counts = recipe_mex.select(f.explode('des_clean').alias('col')).groupBy('col').count()\n",
    "mex_des_freq = mex_counts.orderBy(mex_counts[\"count\"].desc()).limit(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+---------+-----+---------+-----+\n",
      "|      col|count|      col|count|      col|count|\n",
      "+---------+-----+---------+-----+---------+-----+\n",
      "|   indian|  129|  italian|   84|  chicken|  132|\n",
      "|    curry|  107|    sauce|   69|   cheese|   83|\n",
      "|     dish|   85|   cheese|   66|     beef|   81|\n",
      "|  chicken|   83|    pasta|   54|   recipe|   79|\n",
      "|   recipe|   62|  chicken|   49|  mexican|   77|\n",
      "|     rice|   54|   recipe|   44|     corn|   72|\n",
      "|     made|   53|     easy|   42|     make|   69|\n",
      "|    spicy|   52|delicious|   39|    sauce|   67|\n",
      "|   spices|   51|   garlic|   37|    beans|   66|\n",
      "|     easy|   45| tomatoes|   36|    salsa|   63|\n",
      "|    sauce|   44|     dish|   35|    spicy|   55|\n",
      "| simmered|   40|   tomato|   35|     easy|   55|\n",
      "|   yogurt|   38|     make|   32|tortillas|   54|\n",
      "|     make|   36|    fresh|   32|     rice|   51|\n",
      "|delicious|   35|    bread|   31|   ground|   49|\n",
      "+---------+-----+---------+-----+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View then in one dataframe\n",
    "from pyspark.sql.functions import monotonically_increasing_id \n",
    "\n",
    "df1 = ind_des_freq.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "df2 = ita_des_freq.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "df3 = mex_des_freq.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "\n",
    "des_freq = df1.join(df2,(\"row_id\")).join(df3,(\"row_id\")).drop(\"row_id\")\n",
    "des_freq.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
