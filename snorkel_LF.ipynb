{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe Labelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up for the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WL0ih9fRhPEh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snorkel\n",
      "  Using cached snorkel-0.9.3-py3-none-any.whl (139 kB)\n",
      "Collecting tqdm<5.0.0,>=4.33.0\n",
      "  Using cached tqdm-4.43.0-py2.py3-none-any.whl (59 kB)\n",
      "Collecting torch<1.2.0,>=1.1.0\n",
      "  Using cached torch-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (676.9 MB)\n",
      "Collecting pandas<0.26.0,>=0.25.0\n",
      "  Using cached pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4 MB)\n",
      "Collecting munkres==1.1.2\n",
      "  Using cached munkres-1.1.2-py2.py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.16.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from snorkel) (1.18.1)\n",
      "Processing /home/faculty/.cache/pip/wheels/81/dc/bb/fbde77ddcbf8d5a04787faf6cc9f1edf4c70a67961d7c75abf/networkx-2.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.2.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from snorkel) (1.4.1)\n",
      "Collecting scikit-learn<0.22.0,>=0.20.2\n",
      "  Using cached scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7 MB)\n",
      "Collecting tensorboardX<2.0,>=1.6\n",
      "  Using cached tensorboardX-1.9-py2.py3-none-any.whl (190 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from pandas<0.26.0,>=0.25.0->snorkel) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from pandas<0.26.0,>=0.25.0->snorkel) (2019.3)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from networkx<2.4,>=2.2->snorkel) (4.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from scikit-learn<0.22.0,>=0.20.2->snorkel) (0.14.1)\n",
      "Requirement already satisfied: six in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from tensorboardX<2.0,>=1.6->snorkel) (1.14.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from tensorboardX<2.0,>=1.6->snorkel) (3.11.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from protobuf>=3.8.0->tensorboardX<2.0,>=1.6->snorkel) (45.2.0.post20200210)\n",
      "\u001b[31mERROR: faculty-models 0.1.1 has requirement mlflow-faculty>=0.4.3, but you'll have mlflow-faculty 0.4.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tqdm, torch, pandas, munkres, networkx, scikit-learn, tensorboardX, snorkel\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.0.1\n",
      "    Uninstalling pandas-1.0.1:\n",
      "      Successfully uninstalled pandas-1.0.1\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 2.4\n",
      "    Uninstalling networkx-2.4:\n",
      "      Successfully uninstalled networkx-2.4\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22.1\n",
      "    Uninstalling scikit-learn-0.22.1:\n",
      "      Successfully uninstalled scikit-learn-0.22.1\n",
      "Successfully installed munkres-1.1.2 networkx-2.3 pandas-0.25.3 scikit-learn-0.21.3 snorkel-0.9.3 tensorboardX-1.9 torch-1.1.0 tqdm-4.43.0\n"
     ]
    }
   ],
   "source": [
    "! pip install snorkel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RzMzZ5c8hPEn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-2.2.3-cp36-cp36m-manylinux1_x86_64.whl (10.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.4 MB 39.7 MB/s eta 0:00:01    |█████████████                   | 4.2 MB 39.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wasabi<1.1.0,>=0.4.0\n",
      "  Downloading wasabi-0.6.0-py3-none-any.whl (20 kB)\n",
      "Collecting blis<0.5.0,>=0.4.0\n",
      "  Downloading blis-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (3.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7 MB 42.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting catalogue<1.1.0,>=0.0.7\n",
      "  Downloading catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy) (2.22.0)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.2-cp36-cp36m-manylinux1_x86_64.whl (19 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.3-cp36-cp36m-manylinux1_x86_64.whl (32 kB)\n",
      "Collecting thinc<7.4.0,>=7.3.0\n",
      "  Downloading thinc-7.3.1-cp36-cp36m-manylinux1_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 83.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy) (1.18.1)\n",
      "Collecting srsly<1.1.0,>=0.1.0\n",
      "  Downloading srsly-1.0.2-cp36-cp36m-manylinux1_x86_64.whl (185 kB)\n",
      "\u001b[K     |████████████████████████████████| 185 kB 93.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (119 kB)\n",
      "\u001b[K     |████████████████████████████████| 119 kB 95.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting plac<1.2.0,>=0.9.6\n",
      "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy) (45.2.0.post20200210)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from thinc<7.4.0,>=7.3.0->spacy) (4.43.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (2.2.0)\n",
      "Installing collected packages: wasabi, blis, catalogue, murmurhash, cymem, preshed, srsly, plac, thinc, spacy\n",
      "Successfully installed blis-0.4.1 catalogue-1.0.0 cymem-2.0.3 murmurhash-1.0.2 plac-1.1.3 preshed-3.0.2 spacy-2.2.3 srsly-1.0.2 thinc-7.3.1 wasabi-0.6.0\n"
     ]
    }
   ],
   "source": [
    "! pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "id": "PcrYo7xyhPEp",
    "outputId": "a176c5e6-0d61-4668-826a-c9e011f13ddc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.2.5\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.0 MB 727 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from en_core_web_sm==2.2.5) (2.2.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (45.2.0.post20200210)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.3.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.5.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.43.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.2.0)\n",
      "Building wheels for collected packages: en-core-web-sm\n",
      "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.2.5-py3-none-any.whl size=12011738 sha256=f37dbee787d66b4d4e0bc953ef5f1a30477462791ed258fd6017f7fa8bf7b7d7\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-7sl889qo/wheels/b5/94/56/596daa677d7e91038cbddfcf32b591d0c915a1b3a3e3d3c79d\n",
      "Successfully built en-core-web-sm\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-2.2.5\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "tdbski8thPFQ",
    "outputId": "83732d81-a32c-4f55-d41c-6d54f8765fcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (3.4.5)\n",
      "Requirement already satisfied: six in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from nltk) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "Byvg_0k7hPFU",
    "outputId": "265e81ea-f562-4559-cf93-488213f3540b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/faculty/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/faculty/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/faculty/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/faculty/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fdZMV8XFyXfL"
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk import sent_tokenize, word_tokenize\n",
    "# from nltk.corpus import stopwords\n",
    "# import re\n",
    "# import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s8NMX7sJBFWa"
   },
   "outputs": [],
   "source": [
    "# Display full output rather than just the last line of output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wVHdxlF4hPFH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "PATH = 'https://raw.githubusercontent.com/uceikow/DataEngineeringGroupAO/master/Recipe_dataset/'\n",
    "\n",
    "indian = pd.read_json(PATH + \"data_indian.json\")\n",
    "indian['label'] = 'indian'\n",
    "italian = pd.read_json(PATH + \"data_italian.json\")\n",
    "italian['label'] = 'italian'\n",
    "mexican = pd.read_json(PATH + \"data_mexican.json\")\n",
    "mexican['label'] = 'mexican'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "620"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length of each dataset\n",
    "len(indian)\n",
    "len(mexican)\n",
    "len(italian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "colab_type": "code",
    "id": "iYDYOIHqqi3z",
    "outputId": "d20da84c-cb5f-48e9-a199-384b58180452"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indian Peanut Stew</td>\n",
       "      <td>This is an easy, authentic dish from South Asi...</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Roomali Roti</td>\n",
       "      <td>There is no leavening in this simple, tender I...</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spicy Sweet Potato Salad</td>\n",
       "      <td>It's important to use good mayonnaise in this ...</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicken Saag</td>\n",
       "      <td>The classic Indian chicken and spinach dish ge...</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paleo Slow Cooker Pork Loin</td>\n",
       "      <td>Boneless pork loin slowly cooks in a curried f...</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>Taco Stew</td>\n",
       "      <td>Ground beef and onions sauteed with a packet o...</td>\n",
       "      <td>mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>Chicken Tortilla Soup in the Slow Cooker</td>\n",
       "      <td>Everyone loves using their slow cooker to make...</td>\n",
       "      <td>mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>Bountiful Garden Zucchini Enchiladas</td>\n",
       "      <td>Fresh zucchini and Monterey Jack cheese filled...</td>\n",
       "      <td>mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>Bean and Honey Burrito Casserole</td>\n",
       "      <td>Here's a great way to feed burritos to a crowd...</td>\n",
       "      <td>mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>Green Chile Chicken Stew</td>\n",
       "      <td>This stew will keep you warm and cozy on those...</td>\n",
       "      <td>mexican</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Title  \\\n",
       "0                           Indian Peanut Stew   \n",
       "1                                 Roomali Roti   \n",
       "2                     Spicy Sweet Potato Salad   \n",
       "3                                 Chicken Saag   \n",
       "4                  Paleo Slow Cooker Pork Loin   \n",
       "...                                        ...   \n",
       "1495                                 Taco Stew   \n",
       "1496  Chicken Tortilla Soup in the Slow Cooker   \n",
       "1497      Bountiful Garden Zucchini Enchiladas   \n",
       "1498          Bean and Honey Burrito Casserole   \n",
       "1499                  Green Chile Chicken Stew   \n",
       "\n",
       "                                            Description    label  \n",
       "0     This is an easy, authentic dish from South Asi...   indian  \n",
       "1     There is no leavening in this simple, tender I...   indian  \n",
       "2     It's important to use good mayonnaise in this ...   indian  \n",
       "3     The classic Indian chicken and spinach dish ge...   indian  \n",
       "4     Boneless pork loin slowly cooks in a curried f...   indian  \n",
       "...                                                 ...      ...  \n",
       "1495  Ground beef and onions sauteed with a packet o...  mexican  \n",
       "1496  Everyone loves using their slow cooker to make...  mexican  \n",
       "1497  Fresh zucchini and Monterey Jack cheese filled...  mexican  \n",
       "1498  Here's a great way to feed burritos to a crowd...  mexican  \n",
       "1499  This stew will keep you warm and cozy on those...  mexican  \n",
       "\n",
       "[1500 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat them into one dataset\n",
    "recipe = pd.concat([indian, italian, mexican],ignore_index = True)\n",
    "recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5B5GRAyfhPFS"
   },
   "source": [
    "## Clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BsgxdYe9p-TS"
   },
   "outputs": [],
   "source": [
    "# Clean the dataset\n",
    "# Lowercase\n",
    "recipe = recipe.apply(lambda row: row.str.lower())\n",
    "\n",
    "# Remove digits\n",
    "recipe['Title'] = recipe.apply((lambda row: ''.join([i for i in row['Title'] if not i.isdigit()])),axis = 1)\n",
    "recipe['Description'] = recipe.apply((lambda row: ''.join([i for i in row['Description'] if not i.isdigit()])),axis = 1)\n",
    "\n",
    "# Remove punctuations\n",
    "recipe['Title'] = recipe.apply((lambda row: ''.join([i for i in row['Title'] if i not in string.punctuation])),axis=1)\n",
    "recipe['Description'] = recipe.apply((lambda row: ''.join([i for i in row['Description'] if i not in string.punctuation])),axis=1)\n",
    "\n",
    "# Remove Stopwords\n",
    "stop = stopwords.words('english')\n",
    "recipe['Title'] = recipe['Title'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "recipe['Description'] = recipe['Description'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "rPeGEU8Z5dIZ",
    "outputId": "160cab6b-5b0c-4022-a98e-74d282eca748"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indian peanut stew</td>\n",
       "      <td>easy authentic dish south asia appeals wide ra...</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roomali roti</td>\n",
       "      <td>leavening simple tender indian flatbread bread...</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spicy sweet potato salad</td>\n",
       "      <td>important use good mayonnaise recipe let cooke...</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chicken saag</td>\n",
       "      <td>classic indian chicken spinach dish gets richn...</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paleo slow cooker pork loin</td>\n",
       "      <td>boneless pork loin slowly cooks curried fruit ...</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Title  \\\n",
       "0           indian peanut stew   \n",
       "1                 roomali roti   \n",
       "2     spicy sweet potato salad   \n",
       "3                 chicken saag   \n",
       "4  paleo slow cooker pork loin   \n",
       "\n",
       "                                         Description   label  \n",
       "0  easy authentic dish south asia appeals wide ra...  indian  \n",
       "1  leavening simple tender indian flatbread bread...  indian  \n",
       "2  important use good mayonnaise recipe let cooke...  indian  \n",
       "3  classic indian chicken spinach dish gets richn...  indian  \n",
       "4  boneless pork loin slowly cooks curried fruit ...  indian  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hOFD7g02CwKl"
   },
   "source": [
    "## Pattern Exploration\n",
    "\n",
    "Before splitting the dataset and writing labelling function,  we might want to first get an idea of how our targetting labels look like. This gives us some basic information of how to start building the labelling function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 701
    },
    "colab_type": "code",
    "id": "BgzIrjKY9S9x",
    "outputId": "53f64bd4-685d-4e7a-fb91-775fb02ef590"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indian</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Italian</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Mexican</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chicken</td>\n",
       "      <td>92</td>\n",
       "      <td>italian</td>\n",
       "      <td>76</td>\n",
       "      <td>chicken</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>curry</td>\n",
       "      <td>82</td>\n",
       "      <td>chicken</td>\n",
       "      <td>52</td>\n",
       "      <td>mexican</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indian</td>\n",
       "      <td>72</td>\n",
       "      <td>pasta</td>\n",
       "      <td>45</td>\n",
       "      <td>enchiladas</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>masala</td>\n",
       "      <td>30</td>\n",
       "      <td>sauce</td>\n",
       "      <td>38</td>\n",
       "      <td>taco</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rice</td>\n",
       "      <td>28</td>\n",
       "      <td>lasagna</td>\n",
       "      <td>33</td>\n",
       "      <td>soup</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spicy</td>\n",
       "      <td>25</td>\n",
       "      <td>sausage</td>\n",
       "      <td>23</td>\n",
       "      <td>bean</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>curried</td>\n",
       "      <td>21</td>\n",
       "      <td>pizza</td>\n",
       "      <td>23</td>\n",
       "      <td>salsa</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>paneer</td>\n",
       "      <td>20</td>\n",
       "      <td>ii</td>\n",
       "      <td>23</td>\n",
       "      <td>casserole</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chutney</td>\n",
       "      <td>20</td>\n",
       "      <td>spaghetti</td>\n",
       "      <td>19</td>\n",
       "      <td>beef</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>soup</td>\n",
       "      <td>20</td>\n",
       "      <td>bread</td>\n",
       "      <td>18</td>\n",
       "      <td>rice</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>salad</td>\n",
       "      <td>19</td>\n",
       "      <td>cheese</td>\n",
       "      <td>17</td>\n",
       "      <td>tacos</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>easy</td>\n",
       "      <td>19</td>\n",
       "      <td>soup</td>\n",
       "      <td>16</td>\n",
       "      <td>easy</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lamb</td>\n",
       "      <td>17</td>\n",
       "      <td>tomato</td>\n",
       "      <td>16</td>\n",
       "      <td>enchilada</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tomato</td>\n",
       "      <td>17</td>\n",
       "      <td>salad</td>\n",
       "      <td>13</td>\n",
       "      <td>dip</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>potato</td>\n",
       "      <td>16</td>\n",
       "      <td>easy</td>\n",
       "      <td>12</td>\n",
       "      <td>ii</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Indian  Frequency    Italian  Frequency     Mexican  Frequency\n",
       "0   chicken         92    italian         76     chicken        118\n",
       "1     curry         82    chicken         52     mexican        100\n",
       "2    indian         72      pasta         45  enchiladas         57\n",
       "3    masala         30      sauce         38        taco         41\n",
       "4      rice         28    lasagna         33        soup         39\n",
       "5     spicy         25    sausage         23        bean         37\n",
       "6   curried         21      pizza         23       salsa         36\n",
       "7    paneer         20         ii         23   casserole         36\n",
       "8   chutney         20  spaghetti         19        beef         31\n",
       "9      soup         20      bread         18        rice         30\n",
       "10    salad         19     cheese         17       tacos         30\n",
       "11     easy         19       soup         16        easy         29\n",
       "12     lamb         17     tomato         16   enchilada         27\n",
       "13   tomato         17      salad         13         dip         27\n",
       "14   potato         16       easy         12          ii         26"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Patterns from different recipes\n",
    "\n",
    "# Filter out different recipes\n",
    "recipe_ind = recipe[recipe['label'] == 'indian']\n",
    "recipe_ita = recipe[recipe['label'] == 'italian']\n",
    "recipe_mex = recipe[recipe['label'] == 'mexican']\n",
    "\n",
    "# Word frequency in 'Title'\n",
    "top_N = 15\n",
    "\n",
    "title1 = recipe_ind.Title.str.cat(sep=' ')\n",
    "words_in_title1 = nltk.tokenize.word_tokenize(title1)\n",
    "word_dist_title1 = nltk.FreqDist(words_in_title1)\n",
    "\n",
    "title2 = recipe_ita.Title.str.cat(sep=' ')\n",
    "words_in_title2 = nltk.tokenize.word_tokenize(title2)\n",
    "word_dist_title2 = nltk.FreqDist(words_in_title2)\n",
    "\n",
    "title3 = recipe_mex.Title.str.cat(sep=' ')\n",
    "words_in_title3 = nltk.tokenize.word_tokenize(title3)\n",
    "word_dist_title3 = nltk.FreqDist(words_in_title3)\n",
    "\n",
    "ind_freq = pd.DataFrame(word_dist_title1.most_common(top_N),\n",
    "                    columns=['Indian', 'Frequency'])\n",
    "ita_freq = pd.DataFrame(word_dist_title2.most_common(top_N),\n",
    "                    columns=['Italian', 'Frequency'])\n",
    "mex_freq = pd.DataFrame(word_dist_title3.most_common(top_N),\n",
    "                    columns=['Mexican', 'Frequency'])\n",
    "\n",
    "title_freq = pd.concat([ind_freq,ita_freq,mex_freq],axis = 1)\n",
    "title_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easier to find patterns and differences of recipes if we display titles of three recipes together. The same goes for description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ind_description</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Ita_description</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Mex_description</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indian</td>\n",
       "      <td>119</td>\n",
       "      <td>italian</td>\n",
       "      <td>79</td>\n",
       "      <td>chicken</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>curry</td>\n",
       "      <td>101</td>\n",
       "      <td>sauce</td>\n",
       "      <td>63</td>\n",
       "      <td>beef</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dish</td>\n",
       "      <td>83</td>\n",
       "      <td>cheese</td>\n",
       "      <td>61</td>\n",
       "      <td>recipe</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chicken</td>\n",
       "      <td>80</td>\n",
       "      <td>pasta</td>\n",
       "      <td>51</td>\n",
       "      <td>cheese</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recipe</td>\n",
       "      <td>61</td>\n",
       "      <td>chicken</td>\n",
       "      <td>49</td>\n",
       "      <td>mexican</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rice</td>\n",
       "      <td>53</td>\n",
       "      <td>recipe</td>\n",
       "      <td>43</td>\n",
       "      <td>corn</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spicy</td>\n",
       "      <td>51</td>\n",
       "      <td>easy</td>\n",
       "      <td>41</td>\n",
       "      <td>make</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spices</td>\n",
       "      <td>50</td>\n",
       "      <td>garlic</td>\n",
       "      <td>36</td>\n",
       "      <td>sauce</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>made</td>\n",
       "      <td>48</td>\n",
       "      <td>tomatoes</td>\n",
       "      <td>35</td>\n",
       "      <td>beans</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sauce</td>\n",
       "      <td>44</td>\n",
       "      <td>dish</td>\n",
       "      <td>35</td>\n",
       "      <td>salsa</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>easy</td>\n",
       "      <td>41</td>\n",
       "      <td>delicious</td>\n",
       "      <td>35</td>\n",
       "      <td>spicy</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>simmered</td>\n",
       "      <td>39</td>\n",
       "      <td>make</td>\n",
       "      <td>31</td>\n",
       "      <td>tortillas</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>yogurt</td>\n",
       "      <td>36</td>\n",
       "      <td>tomato</td>\n",
       "      <td>31</td>\n",
       "      <td>easy</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>potatoes</td>\n",
       "      <td>35</td>\n",
       "      <td>fresh</td>\n",
       "      <td>29</td>\n",
       "      <td>ground</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>make</td>\n",
       "      <td>35</td>\n",
       "      <td>bread</td>\n",
       "      <td>29</td>\n",
       "      <td>rice</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>delicious</td>\n",
       "      <td>34</td>\n",
       "      <td>and…</td>\n",
       "      <td>28</td>\n",
       "      <td>great</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>coconut</td>\n",
       "      <td>31</td>\n",
       "      <td>baked</td>\n",
       "      <td>28</td>\n",
       "      <td>made</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>and…</td>\n",
       "      <td>27</td>\n",
       "      <td>creamy</td>\n",
       "      <td>25</td>\n",
       "      <td>tomatoes</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cumin</td>\n",
       "      <td>27</td>\n",
       "      <td>lasagna</td>\n",
       "      <td>25</td>\n",
       "      <td>taco</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sweet</td>\n",
       "      <td>26</td>\n",
       "      <td>great</td>\n",
       "      <td>24</td>\n",
       "      <td>and…</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ind_description  Frequency Ita_description  Frequency Mex_description  \\\n",
       "0           indian        119         italian         79         chicken   \n",
       "1            curry        101           sauce         63            beef   \n",
       "2             dish         83          cheese         61          recipe   \n",
       "3          chicken         80           pasta         51          cheese   \n",
       "4           recipe         61         chicken         49         mexican   \n",
       "5             rice         53          recipe         43            corn   \n",
       "6            spicy         51            easy         41            make   \n",
       "7           spices         50          garlic         36           sauce   \n",
       "8             made         48        tomatoes         35           beans   \n",
       "9            sauce         44            dish         35           salsa   \n",
       "10            easy         41       delicious         35           spicy   \n",
       "11        simmered         39            make         31       tortillas   \n",
       "12          yogurt         36          tomato         31            easy   \n",
       "13        potatoes         35           fresh         29          ground   \n",
       "14            make         35           bread         29            rice   \n",
       "15       delicious         34            and…         28           great   \n",
       "16         coconut         31           baked         28            made   \n",
       "17            and…         27          creamy         25        tomatoes   \n",
       "18           cumin         27         lasagna         25            taco   \n",
       "19           sweet         26           great         24            and…   \n",
       "\n",
       "    Frequency  \n",
       "0         126  \n",
       "1          77  \n",
       "2          77  \n",
       "3          76  \n",
       "4          69  \n",
       "5          68  \n",
       "6          68  \n",
       "7          64  \n",
       "8          62  \n",
       "9          58  \n",
       "10         53  \n",
       "11         53  \n",
       "12         51  \n",
       "13         48  \n",
       "14         47  \n",
       "15         46  \n",
       "16         42  \n",
       "17         42  \n",
       "18         40  \n",
       "19         39  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word frequency in 'Description'\n",
    "top_N =20\n",
    "\n",
    "des1 = recipe_ind.Description.str.cat(sep=' ')\n",
    "words_in_des1 = nltk.tokenize.word_tokenize(des1)\n",
    "word_dist_des1 = nltk.FreqDist(words_in_des1)\n",
    "\n",
    "des2 = recipe_ita.Description.str.cat(sep=' ')\n",
    "words_in_des2 = nltk.tokenize.word_tokenize(des2)\n",
    "word_dist_des2 = nltk.FreqDist(words_in_des2)\n",
    "\n",
    "des3 = recipe_mex.Description.str.cat(sep=' ')\n",
    "words_in_des3 = nltk.tokenize.word_tokenize(des3)\n",
    "word_dist_des3 = nltk.FreqDist(words_in_des3)\n",
    "\n",
    "d1_freq = pd.DataFrame(word_dist_des1.most_common(top_N),\n",
    "                    columns=['Ind_description', 'Frequency'])\n",
    "d2_freq = pd.DataFrame(word_dist_des2.most_common(top_N),\n",
    "                    columns=['Ita_description', 'Frequency'])\n",
    "d3_freq = pd.DataFrame(word_dist_des3.most_common(top_N),\n",
    "                    columns=['Mex_description', 'Frequency'])\n",
    "\n",
    "des_freq = pd.concat([d1_freq,d2_freq,d3_freq],axis=1)\n",
    "des_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point, we see that there are something more to do with data cleaning. \n",
    "\n",
    "- Get rid of those \" ...\"\n",
    "- Are Verbs, Conjuctions and prepositions important in our case, if not, we can clear them, only leaving Nouns in our dataset.\n",
    "- Stemming words (*curry* and *curried* should be of the same thing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Re-clean the dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is scraped from an online recipe website. We only captured part of the description, and some of them contains \"…\" if the sentence does not ended when capped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"...\" from description\n",
    "recipe['Description'] = recipe.Description.apply(lambda x: re.sub(r'…','',x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part-pf-speech is used to remove verbs, prepositions, conjunctions from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove verb, prepositions, conjunctions from the text\n",
    "\n",
    "# Part of speech\n",
    "recipe['tokens'] = recipe.Description.apply(lambda x: nltk.word_tokenize(x))\n",
    "recipe['tagged'] = recipe.tokens.apply(lambda x: nltk.pos_tag(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define remove function\n",
    "def re_pos(tuple_list):\n",
    "    for i in tuple_list:\n",
    "        if i[1] in ['VB','VBD','VBG','VBN','VBP','VBZ','CC','IN']:\n",
    "            tuple_list.remove(i)\n",
    "    return tuple_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted words and change tokens\n",
    "recipe['tagged'] = recipe.tagged.apply(lambda x: re_pos(x))\n",
    "recipe['tokens'] = recipe.tagged.apply(lambda x: [i[0] for i in x])\n",
    "recipe['Description'] = recipe.tokens.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indian peanut stew</td>\n",
       "      <td>easy authentic dish south asia appeals wide ra...</td>\n",
       "      <td>indian</td>\n",
       "      <td>[easy, authentic, dish, south, asia, appeals, ...</td>\n",
       "      <td>[(easy, JJ), (authentic, JJ), (dish, NN), (sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roomali roti</td>\n",
       "      <td>simple tender indian flatbread flour oil salt</td>\n",
       "      <td>indian</td>\n",
       "      <td>[simple, tender, indian, flatbread, flour, oil...</td>\n",
       "      <td>[(simple, JJ), (tender, NN), (indian, JJ), (fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spicy sweet potato salad</td>\n",
       "      <td>important use good mayonnaise recipe let potatoes</td>\n",
       "      <td>indian</td>\n",
       "      <td>[important, use, good, mayonnaise, recipe, let...</td>\n",
       "      <td>[(important, JJ), (use, NN), (good, JJ), (mayo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chicken saag</td>\n",
       "      <td>classic indian chicken spinach dish richness s...</td>\n",
       "      <td>indian</td>\n",
       "      <td>[classic, indian, chicken, spinach, dish, rich...</td>\n",
       "      <td>[(classic, JJ), (indian, JJ), (chicken, NN), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paleo slow cooker pork loin</td>\n",
       "      <td>boneless pork slowly cooks fruit sauce tender ...</td>\n",
       "      <td>indian</td>\n",
       "      <td>[boneless, pork, slowly, cooks, fruit, sauce, ...</td>\n",
       "      <td>[(boneless, NN), (pork, NN), (slowly, RB), (co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Title  \\\n",
       "0           indian peanut stew   \n",
       "1                 roomali roti   \n",
       "2     spicy sweet potato salad   \n",
       "3                 chicken saag   \n",
       "4  paleo slow cooker pork loin   \n",
       "\n",
       "                                         Description   label  \\\n",
       "0  easy authentic dish south asia appeals wide ra...  indian   \n",
       "1      simple tender indian flatbread flour oil salt  indian   \n",
       "2  important use good mayonnaise recipe let potatoes  indian   \n",
       "3  classic indian chicken spinach dish richness s...  indian   \n",
       "4  boneless pork slowly cooks fruit sauce tender ...  indian   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [easy, authentic, dish, south, asia, appeals, ...   \n",
       "1  [simple, tender, indian, flatbread, flour, oil...   \n",
       "2  [important, use, good, mayonnaise, recipe, let...   \n",
       "3  [classic, indian, chicken, spinach, dish, rich...   \n",
       "4  [boneless, pork, slowly, cooks, fruit, sauce, ...   \n",
       "\n",
       "                                              tagged  \n",
       "0  [(easy, JJ), (authentic, JJ), (dish, NN), (sou...  \n",
       "1  [(simple, JJ), (tender, NN), (indian, JJ), (fl...  \n",
       "2  [(important, JJ), (use, NN), (good, JJ), (mayo...  \n",
       "3  [(classic, JJ), (indian, JJ), (chicken, NN), (...  \n",
       "4  [(boneless, NN), (pork, NN), (slowly, RB), (co...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After re-cleaning, let's see the change of patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ind_description</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Ita_description</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Mex_description</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indian</td>\n",
       "      <td>129</td>\n",
       "      <td>italian</td>\n",
       "      <td>84</td>\n",
       "      <td>chicken</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>curry</td>\n",
       "      <td>96</td>\n",
       "      <td>cheese</td>\n",
       "      <td>66</td>\n",
       "      <td>beef</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dish</td>\n",
       "      <td>84</td>\n",
       "      <td>sauce</td>\n",
       "      <td>57</td>\n",
       "      <td>cheese</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chicken</td>\n",
       "      <td>73</td>\n",
       "      <td>pasta</td>\n",
       "      <td>51</td>\n",
       "      <td>mexican</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recipe</td>\n",
       "      <td>58</td>\n",
       "      <td>recipe</td>\n",
       "      <td>43</td>\n",
       "      <td>corn</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rice</td>\n",
       "      <td>53</td>\n",
       "      <td>chicken</td>\n",
       "      <td>42</td>\n",
       "      <td>recipe</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spices</td>\n",
       "      <td>51</td>\n",
       "      <td>easy</td>\n",
       "      <td>42</td>\n",
       "      <td>beans</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spicy</td>\n",
       "      <td>51</td>\n",
       "      <td>delicious</td>\n",
       "      <td>39</td>\n",
       "      <td>spicy</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>easy</td>\n",
       "      <td>43</td>\n",
       "      <td>tomatoes</td>\n",
       "      <td>35</td>\n",
       "      <td>sauce</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yogurt</td>\n",
       "      <td>38</td>\n",
       "      <td>garlic</td>\n",
       "      <td>34</td>\n",
       "      <td>salsa</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sauce</td>\n",
       "      <td>36</td>\n",
       "      <td>dish</td>\n",
       "      <td>34</td>\n",
       "      <td>easy</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>potatoes</td>\n",
       "      <td>35</td>\n",
       "      <td>tomato</td>\n",
       "      <td>31</td>\n",
       "      <td>tortillas</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>delicious</td>\n",
       "      <td>35</td>\n",
       "      <td>fresh</td>\n",
       "      <td>31</td>\n",
       "      <td>ground</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cumin</td>\n",
       "      <td>29</td>\n",
       "      <td>bread</td>\n",
       "      <td>30</td>\n",
       "      <td>rice</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fresh</td>\n",
       "      <td>29</td>\n",
       "      <td>lasagna</td>\n",
       "      <td>26</td>\n",
       "      <td>great</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>coconut</td>\n",
       "      <td>28</td>\n",
       "      <td>great</td>\n",
       "      <td>25</td>\n",
       "      <td>green</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>masala</td>\n",
       "      <td>26</td>\n",
       "      <td>beef</td>\n",
       "      <td>25</td>\n",
       "      <td>tomatoes</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>milk</td>\n",
       "      <td>26</td>\n",
       "      <td>mozzarella</td>\n",
       "      <td>24</td>\n",
       "      <td>taco</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sweet</td>\n",
       "      <td>25</td>\n",
       "      <td>creamy</td>\n",
       "      <td>23</td>\n",
       "      <td>fresh</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>simple</td>\n",
       "      <td>23</td>\n",
       "      <td>simple</td>\n",
       "      <td>22</td>\n",
       "      <td>onion</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ind_description  Frequency Ita_description  Frequency Mex_description  \\\n",
       "0           indian        129         italian         84         chicken   \n",
       "1            curry         96          cheese         66            beef   \n",
       "2             dish         84           sauce         57          cheese   \n",
       "3          chicken         73           pasta         51         mexican   \n",
       "4           recipe         58          recipe         43            corn   \n",
       "5             rice         53         chicken         42          recipe   \n",
       "6           spices         51            easy         42           beans   \n",
       "7            spicy         51       delicious         39           spicy   \n",
       "8             easy         43        tomatoes         35           sauce   \n",
       "9           yogurt         38          garlic         34           salsa   \n",
       "10           sauce         36            dish         34            easy   \n",
       "11        potatoes         35          tomato         31       tortillas   \n",
       "12       delicious         35           fresh         31          ground   \n",
       "13           cumin         29           bread         30            rice   \n",
       "14           fresh         29         lasagna         26           great   \n",
       "15         coconut         28           great         25           green   \n",
       "16          masala         26            beef         25        tomatoes   \n",
       "17            milk         26      mozzarella         24            taco   \n",
       "18           sweet         25          creamy         23           fresh   \n",
       "19          simple         23          simple         22           onion   \n",
       "\n",
       "    Frequency  \n",
       "0         113  \n",
       "1          80  \n",
       "2          79  \n",
       "3          77  \n",
       "4          72  \n",
       "5          71  \n",
       "6          62  \n",
       "7          54  \n",
       "8          54  \n",
       "9          53  \n",
       "10         53  \n",
       "11         52  \n",
       "12         49  \n",
       "13         49  \n",
       "14         48  \n",
       "15         44  \n",
       "16         41  \n",
       "17         39  \n",
       "18         38  \n",
       "19         37  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Patterns after re-cleaning\n",
    "recipe_ind = recipe[recipe['label'] == 'indian']\n",
    "recipe_ita = recipe[recipe['label'] == 'italian']\n",
    "recipe_mex = recipe[recipe['label'] == 'mexican']\n",
    "\n",
    "top_N =20\n",
    "\n",
    "des1 = recipe_ind.Description.str.cat(sep=' ')\n",
    "words_in_des1 = nltk.tokenize.word_tokenize(des1)\n",
    "word_dist_des1 = nltk.FreqDist(words_in_des1)\n",
    "\n",
    "des2 = recipe_ita.Description.str.cat(sep=' ')\n",
    "words_in_des2 = nltk.tokenize.word_tokenize(des2)\n",
    "word_dist_des2 = nltk.FreqDist(words_in_des2)\n",
    "\n",
    "des3 = recipe_mex.Description.str.cat(sep=' ')\n",
    "words_in_des3 = nltk.tokenize.word_tokenize(des3)\n",
    "word_dist_des3 = nltk.FreqDist(words_in_des3)\n",
    "\n",
    "d1_freq = pd.DataFrame(word_dist_des1.most_common(top_N),\n",
    "                    columns=['Ind_description', 'Frequency'])\n",
    "d2_freq = pd.DataFrame(word_dist_des2.most_common(top_N),\n",
    "                    columns=['Ita_description', 'Frequency'])\n",
    "d3_freq = pd.DataFrame(word_dist_des3.most_common(top_N),\n",
    "                    columns=['Mex_description', 'Frequency'])\n",
    "\n",
    "des_freq = pd.concat([d1_freq,d2_freq,d3_freq],axis=1)\n",
    "des_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "As you might have noticed, indian food and mexican food share some similarities, such as spicy-related words, sauce-related words, rice, etc. This is somewhere that we need to keep an eye on.\n",
    "</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5EEimMn1BXzs"
   },
   "source": [
    "**Ideas of building Labelling functions:**\n",
    "\n",
    "- Single word (specific ones), such as curry, masala, paneer and chutney for indian repice. These words can label one type of recipe quite well because of their specialty (they will not appear in other recipes). Except for words included in top 15 frequency list, they must be other special words, which might need go through the whole dataset to find.\n",
    "\n",
    "- Word combos, such as **curry + chicken = indian** :) You might find that chicken are used a lot in both indian and mexican recipe, while a way to label them might be find a **word combos** (function = special word + main ingrediant).\n",
    "\n",
    "- Unique wordlist difference! Check if any of word are unique for that kind of recipe but not in other recipes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the orginal dataset for further pattern exploration\n",
    "recipe_ex = recipe.copy()\n",
    "recipe = recipe.drop(columns = ['tokens','tagged'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nXbdMtOGEFPi"
   },
   "source": [
    "## Split the dataset\n",
    "\n",
    "As being discussed in group meeting, we split the dataset into training, validation, development and test datasets.\n",
    "\n",
    "If we do multi-labelling, we need to make sure that all datasets above contains same proportion of the 3 recipes. I decided to have 30% labelled data, in which 10% for dev set, 10% for validation set, and the remaining 10% for test set. We left 70% data to training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Agcde9nWCooH"
   },
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "# Use ShuffleStratifiedSplit to ensure same proportion of each dataset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=3, test_size=0.3, random_state=0)\n",
    "\n",
    "# Get different labelled data\n",
    "ind = recipe[recipe['label'] == 'indian']\n",
    "ind.reset_index(drop=True,inplace=True)\n",
    "ita = recipe[recipe['label'] == 'italian']\n",
    "ita.reset_index(drop=True,inplace=True)\n",
    "mex = recipe[recipe['label'] == 'mexican']\n",
    "mex.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# Split function (leave 70% for training)\n",
    "def shuffle_split(df,sss):\n",
    "    X = df[['Title','Description']]\n",
    "    y = df['label']\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "ind_X_train, ind_X_test, ind_y_train, ind_y_test = shuffle_split(ind,sss)\n",
    "ita_X_train, ita_X_test, ita_y_train, ita_y_test = shuffle_split(ita,sss)\n",
    "mex_X_train, mex_X_test, mex_y_train, mex_y_test = shuffle_split(mex,sss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indian:  336 144\n",
      "italian:  280 120\n",
      "mexican:  434 186\n"
     ]
    }
   ],
   "source": [
    "print('indian: ',len(ind_X_train),len(ind_X_test))\n",
    "print('italian: ',len(ita_X_train),len(ita_X_test))\n",
    "print('mexican: ',len(mex_X_train),len(mex_X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-OxgR17ORUlH"
   },
   "outputs": [],
   "source": [
    "# Combine training and test dataset\n",
    "X_train = pd.concat([ind_X_train,ita_X_train,mex_X_train],axis=0)\n",
    "y_train = pd.concat([ind_y_train,ita_y_train,mex_y_train],axis=0)\n",
    "X_test =  pd.concat([ind_X_test,ita_X_test,mex_X_test],axis=0)\n",
    "y_test =  pd.concat([ind_y_test,ita_y_test,mex_y_test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine training dataset\n",
    "train = pd.concat([X_train,y_train],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the test dataset for next splitting\n",
    "test = pd.concat([X_test,y_test],axis=1)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split development and validation dataset from test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From randomly sampled test set get dev set and validation set.\n",
    "\n",
    "ind_val, ind_dev = test[:48], test[48:96]\n",
    "ita_val, ita_dev = test[144:184], test[184:224]\n",
    "mex_val, mex_dev = test[264:326], test[326:388]\n",
    "ind_test, ita_test, mex_test = test[96:144],test[224:264],test[388:450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine val, dev and test set\n",
    "\n",
    "val = pd.concat([ind_val,ita_val,mex_val],axis=0)\n",
    "dev = pd.concat([ind_dev,ita_dev,mex_dev],axis=0)\n",
    "test_n = pd.concat([ind_test,ita_test,mex_test],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we split the dataset by different countries, we need to shuffle them before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "train = shuffle(train, random_state = 42)\n",
    "test = shuffle(test_n, random_state = 42)\n",
    "val = shuffle(val, random_state = 42)\n",
    "dev = shuffle(dev, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply LFAnalysis, we need to change labels to number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change labels to number\n",
    "def label_to_num(df):\n",
    "    df.label = df.label.apply(lambda x: 0 if x == 'indian' else(1 if x == 'italian' else 2))\n",
    "    return df\n",
    "    \n",
    "test = label_to_num(test)\n",
    "val = label_to_num(val)\n",
    "dev = label_to_num(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for later training\n",
    "df_train = train.iloc[:,:2]\n",
    "df_val = val.iloc[:,:2]\n",
    "df_dev = dev.iloc[:,:2]\n",
    "Y_val = val.iloc[:,-1].values\n",
    "Y_dev = dev.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labelling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For clarity, we define constants to represent the class labels and abstaining.\n",
    "ABSTAIN = -1\n",
    "INDIAN = 0\n",
    "ITALIAN = 1\n",
    "MEXICAN = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keywords LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_keywords = ['curry','indian','masala','paneer','chutney','curried',\n",
    "                'simmered','cumin','yogurt','coconut']\n",
    "\n",
    "@labeling_function()\n",
    "def indian_keywords(x):\n",
    "        if any(word in x.Title for word in ind_keywords):\n",
    "            return INDIAN\n",
    "        else:\n",
    "            return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique word checking\n",
    "import numpy as np\n",
    "\n",
    "ind_values = np.unique(words_in_des1)\n",
    "ita_values = np.unique(words_in_des2)\n",
    "mex_values = np.unique(words_in_des3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check words in indian but not in mexican and italian\n",
    "word_diff_ind_mex = np.setdiff1d(ind_values,mex_values)\n",
    "word_diff_ind_ita = np.setdiff1d(ind_values,ita_values)\n",
    "word_for_ind = np.intersect1d(word_diff_ind_mex,word_diff_ind_ita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def ind_unique_words(x):\n",
    "        if any(word in x.Description for word in word_for_ind):\n",
    "            return INDIAN\n",
    "        else:\n",
    "            return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Combo curry + meat\n",
    "@labeling_function()\n",
    "def currymeat(x):\n",
    "    return INDIAN if re.search(r\"(?=.*curry)(?=.*(chicken|lamb|beef))\", x.Description, flags=re.I) else ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some words in indian recipe, such as *rice, sauce, etc* might comflict with mexican recipe, however, as country_name + rice / sauce can be a good seperator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# County name + food name\n",
    "@labeling_function()\n",
    "def ind_food(x):\n",
    "    return INDIAN if re.search(r\"(?=.*indian)(?=.*(rice|sauce|potatoes))\", x.Description, flags=re.I) else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1050/1050 [00:03<00:00, 304.50it/s]\n",
      "100%|██████████| 150/150 [00:00<00:00, 297.76it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "lfs = [indian_keywords, currymeat, ind_food, ind_unique_words]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)\n",
    "L_dev = applier.apply(df=df_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>indian_keywords</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.163810</td>\n",
       "      <td>0.152381</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currymeat</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.021905</td>\n",
       "      <td>0.021905</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_food</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.020952</td>\n",
       "      <td>0.020952</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_unique_words</th>\n",
       "      <td>3</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.174286</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  j Polarity  Coverage  Overlaps  Conflicts\n",
       "indian_keywords   0      [0]  0.163810  0.152381        0.0\n",
       "currymeat         1      [0]  0.021905  0.021905        0.0\n",
       "ind_food          2      [0]  0.020952  0.020952        0.0\n",
       "ind_unique_words  3      [0]  0.514286  0.174286        0.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>indian_keywords</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currymeat</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_food</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ind_unique_words</th>\n",
       "      <td>3</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.473333</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>27</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "indian_keywords   0      [0]  0.173333  0.146667        0.0       25   \n",
       "currymeat         1      [0]  0.020000  0.020000        0.0        3   \n",
       "ind_food          2      [0]  0.033333  0.033333        0.0        5   \n",
       "ind_unique_words  3      [0]  0.473333  0.173333        0.0       44   \n",
       "\n",
       "                  Incorrect  Emp. Acc.  \n",
       "indian_keywords           1   0.961538  \n",
       "currymeat                 0   1.000000  \n",
       "ind_food                  0   1.000000  \n",
       "ind_unique_words         27   0.619718  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_dev, lfs=lfs).lf_summary(Y=Y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one misclassified case in the first LF and nearly half misclassified in the third LF. Let's check them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>fish tacos honeycumin cilantro slaw chipotle mayo</td>\n",
       "      <td>whats flavorful tacos stuffed fried tilapia with</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "333  fish tacos honeycumin cilantro slaw chipotle mayo   \n",
       "\n",
       "                                          Description  \n",
       "333  whats flavorful tacos stuffed fried tilapia with  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>hot bean dip</td>\n",
       "      <td>bean dip sooooo good easy always make super</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>taco seasoning ii</td>\n",
       "      <td>mixture little cornstarch closely the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>margaritas rocks</td>\n",
       "      <td>sweet sour tequila triple sec grand marnier sq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>mexican turkey burgers</td>\n",
       "      <td>inspired mexican tortillas american burgers de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>chicken taco casserole</td>\n",
       "      <td>favorite taco fixings crowdpleasing casserole ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>mrs espys enchilada sauce</td>\n",
       "      <td>tomato sauce water seasonings browned flour ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>mexican lasagna lite</td>\n",
       "      <td>light ingredients refried beans enchilada sour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>carrot chile cilantro soup</td>\n",
       "      <td>delicious soup combines carrots potatoes garli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>turkey posole</td>\n",
       "      <td>authentic rural mexican dish usually prepared ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>pico de gallo</td>\n",
       "      <td>fresh tomato salsa red onion jalapeno lime jui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>quick easy minute chicken posole</td>\n",
       "      <td>strips breast simmered chicken broth green chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>mexican whole wheat flour tortillas</td>\n",
       "      <td>mexican tortillas fajitas quesadillas mexican ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>beccas taco soup</td>\n",
       "      <td>taco ingredients ground beef onion corn kidney...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>beef bean chimichangas</td>\n",
       "      <td>awesome recipe mexican food tasty beef bean tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>sour cream enchiladas</td>\n",
       "      <td>sour cream cream chicken soup tasty sauce chee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>cinnamon lime chicken fajitas</td>\n",
       "      <td>potatoes breast meat warm lively seasonings fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Title  \\\n",
       "379                         hot bean dip   \n",
       "348                    taco seasoning ii   \n",
       "370                     margaritas rocks   \n",
       "365               mexican turkey burgers   \n",
       "369               chicken taco casserole   \n",
       "346            mrs espys enchilada sauce   \n",
       "380                 mexican lasagna lite   \n",
       "355           carrot chile cilantro soup   \n",
       "331                        turkey posole   \n",
       "349                        pico de gallo   \n",
       "352     quick easy minute chicken posole   \n",
       "336  mexican whole wheat flour tortillas   \n",
       "327                     beccas taco soup   \n",
       "357               beef bean chimichangas   \n",
       "353                sour cream enchiladas   \n",
       "329        cinnamon lime chicken fajitas   \n",
       "\n",
       "                                           Description  \n",
       "379        bean dip sooooo good easy always make super  \n",
       "348              mixture little cornstarch closely the  \n",
       "370  sweet sour tequila triple sec grand marnier sq...  \n",
       "365  inspired mexican tortillas american burgers de...  \n",
       "369  favorite taco fixings crowdpleasing casserole ...  \n",
       "346  tomato sauce water seasonings browned flour ch...  \n",
       "380     light ingredients refried beans enchilada sour  \n",
       "355  delicious soup combines carrots potatoes garli...  \n",
       "331  authentic rural mexican dish usually prepared ...  \n",
       "349  fresh tomato salsa red onion jalapeno lime jui...  \n",
       "352  strips breast simmered chicken broth green chi...  \n",
       "336  mexican tortillas fajitas quesadillas mexican ...  \n",
       "327  taco ingredients ground beef onion corn kidney...  \n",
       "357  awesome recipe mexican food tasty beef bean tr...  \n",
       "353  sour cream cream chicken soup tasty sauce chee...  \n",
       "329  potatoes breast meat warm lively seasonings fi...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.analysis import get_label_buckets\n",
    "\n",
    "buckets1 = get_label_buckets(Y_dev, L_dev[:, 0])\n",
    "df_dev.iloc[buckets1[(MEXICAN, INDIAN)]]\n",
    "\n",
    "buckets2 = get_label_buckets(Y_dev, L_dev[:, 3])\n",
    "df_dev.iloc[buckets2[(MEXICAN, INDIAN)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It mixed with mexican recipe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Italian recipies and attempt to multilabel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From labelling indian part we take the same approach and apply it to label italian dishes. Firstly, attemtpt is made to make multilabelling in one function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ita_keywords = ['pasta','mozzarella', 'lasagna','pesto','dente', 'pizza']\n",
    "\n",
    "@labeling_function()\n",
    "def italian_keywords(x):\n",
    "        if any(word in x.Title for word in ita_keywords):\n",
    "            return ITALIAN\n",
    "        else:\n",
    "            return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Combo curry + meat\n",
    "@labeling_function()\n",
    "def pasta_with(x):\n",
    "    return ITALIAN if re.search(r\"(?=.*pasta)(?=.*(chicken|lamb|beef|pesto|creamy|shrimps|cheese))\", x.Description, flags=re.I) else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1050 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1050/1050 [00:00<00:00, 5778.91it/s][A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 150/150 [00:00<00:00, 5315.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>combination</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.227619</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pasta_with</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.019048</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             j Polarity  Coverage  Overlaps  Conflicts\n",
       "combination  0   [0, 1]  0.227619  0.005714        0.0\n",
       "pasta_with   1      [1]  0.019048  0.005714        0.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>combination</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pasta_with</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             j Polarity  Coverage  Overlaps  Conflicts  Correct  Incorrect  \\\n",
       "combination  0   [0, 1]      0.24       0.0        0.0       33          3   \n",
       "pasta_with   1       []      0.00       0.0        0.0        0          0   \n",
       "\n",
       "             Emp. Acc.  \n",
       "combination   0.916667  \n",
       "pasta_with    0.000000  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lf_combo = [italian_keywords,pasta_with]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lf_combo)\n",
    "L_train = applier.apply(df=df_train)\n",
    "L_dev = applier.apply(df=df_dev)\n",
    "\n",
    "LFAnalysis(L=L_train, lfs=lf_combo).lf_summary()\n",
    "LFAnalysis(L=L_dev, lfs=lf_combo).lf_summary(Y=Y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD LF applier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "snorkel_lf.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
