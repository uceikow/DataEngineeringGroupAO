{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    <br style =\"font-family:UCL-SoM-Outline;color:#EA7600\"> GROUP COURSEWORK </br> \n",
    "    </p>\n",
    "    \n",
    "    \n",
    "    \n",
    "</h1>\n",
    "\n",
    "<div class=\"image\">\n",
    "\n",
    "<h4>\n",
    "          <p style=\"font-size:18pt\">MSIN0166: Data Engineering</p>\n",
    "              <p style=\"font-size:18pt\">Student Name:</p>\n",
    "\n",
    "         \n",
    "  <p>Dominik Wojciechowski</p>        \n",
    "    <p>Junli Zhu</p>\n",
    "    <p>Michał Kowalski</p>\n",
    "    <p>Maxim Mazurov</p>\n",
    "    <p>lanxin Zhang</p> \n",
    "          \n",
    "\n",
    "</h4>\n",
    "\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare the problem \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "With the popularity of online social media, more and more people are willing to share their lives on social platforms, among them sharing recipes has become a very popular activity.In a wide variety of recipes, how can we infer from the name of the recipe or the key words in the recipe description to know which country it is from? \n",
    "\n",
    "But now there are a lot of recipes on the Internet that are not labeled.\n",
    "If we can tell which country the recipe belongs to by its description and title, we can indirectly infer which country's food is currently the most popular on social media.\n",
    "\n",
    "For this group assignment, we decide to use different recipes from three countries(India, Italy and Mexico).  We want to do the multi-labeling on those recipes with their correct country. \n",
    "\n",
    "First of all, we extract the data we from 'allrecipes' website through scraper and stored them in a dataset.Then, we use pyspark to transfered the dataset into RDD. Thirdly, we do the data cleaning and data preparation for lableling function by using Spark. Finally, we apply label function on those prepared data and get the result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Simple Scraper\n",
    "()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Convert Dataset to RDD\n",
    "RDDs are the building blocks of Spark. This part, we will transfer the dataset which we get from the website into RDD.\n",
    "\n",
    "### PySpark Environment Preparation\n",
    "Firstly, we bulit a PySpark environment by installing some essential library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "import pyspark\n",
    "\n",
    "number_cores = int(os.environ['NUM_CPUS'])\n",
    "memory_gb = int(os.environ['AVAILABLE_MEMORY_MB']) // 1024\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setMaster('local[{}]'.format(number_cores))\n",
    "        .set('spark.driver.memory', '{}g'.format(memory_gb))\n",
    ")\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[4] appName=pyspark-shell>\n"
     ]
    }
   ],
   "source": [
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Dataset for RDD\n",
    "\n",
    "Then we load the datassets and labeled those recipes with their countries. Because for this project we will do the multi-label on those recipes so we need do merge those three datasets into one dataset for converting to the RDD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "indian = sqlContext.read.csv(\"/project/Project/DataEngineeringGroupAO/Recipe_dataset/data_indian.csv\",header=True)\n",
    "italian = sqlContext.read.csv(\"/project/Project/DataEngineeringGroupAO/Recipe_dataset/data_italian.csv\",header=True)\n",
    "mexican = sqlContext.read.csv(\"/project/Project/DataEngineeringGroupAO/Recipe_dataset/data_mexican.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label the data\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "indian = indian.withColumn(\"label\",lit(\"indian\"))\n",
    "italian = italian.withColumn(\"label\",lit(\"indian\"))\n",
    "mexican = mexican.withColumn(\"label\",lit(\"mexican\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|               Title|         Description| label|\n",
      "+--------------------+--------------------+------+\n",
      "|  Indian Peanut Stew|This is an easy, ...|indian|\n",
      "|        Roomali Roti|There is no leave...|indian|\n",
      "|Spicy Sweet Potat...|It's important to...|indian|\n",
      "|        Chicken Saag|The classic India...|indian|\n",
      "|Paleo Slow Cooker...|Boneless pork loi...|indian|\n",
      "|Bombay Chicken an...|Chicken parts are...|indian|\n",
      "|Indian Carrots, P...|Potatoes, peas an...|indian|\n",
      "|Wendy's Indian Bu...|This recipe resem...|indian|\n",
      "|    Indian Chickpeas|Garbanzo beans, o...|indian|\n",
      "|Dal Makhani (Indi...|These richly spic...|indian|\n",
      "|               Raita|Chopped tomatoes ...|indian|\n",
      "|Yogurt-Marinated ...|A yogurt-based ma...|indian|\n",
      "|Indian-Spiced Roa...|Spicy roasted chi...|indian|\n",
      "|Cauliflower and T...|Pressed tofu cube...|indian|\n",
      "|Channa Masala (Ch...|This fantastic In...|indian|\n",
      "|Bengali Chicken C...|Thy this deliciou...|indian|\n",
      "|  Indian Sweet Bread|A crisp and sweet...|indian|\n",
      "| Rosy's Palak Paneer|An Indian friend ...|indian|\n",
      "|Roti Bread from I...|This version of t...|indian|\n",
      "|Indian Vegetable ...|Basmati rice enha...|indian|\n",
      "+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indian.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|               Title|         Description| label|\n",
      "+--------------------+--------------------+------+\n",
      "|  Indian Peanut Stew|This is an easy, ...|indian|\n",
      "|        Roomali Roti|There is no leave...|indian|\n",
      "|Spicy Sweet Potat...|It's important to...|indian|\n",
      "|        Chicken Saag|The classic India...|indian|\n",
      "|Paleo Slow Cooker...|Boneless pork loi...|indian|\n",
      "|Bombay Chicken an...|Chicken parts are...|indian|\n",
      "|Indian Carrots, P...|Potatoes, peas an...|indian|\n",
      "|Wendy's Indian Bu...|This recipe resem...|indian|\n",
      "|    Indian Chickpeas|Garbanzo beans, o...|indian|\n",
      "|Dal Makhani (Indi...|These richly spic...|indian|\n",
      "|               Raita|Chopped tomatoes ...|indian|\n",
      "|Yogurt-Marinated ...|A yogurt-based ma...|indian|\n",
      "|Indian-Spiced Roa...|Spicy roasted chi...|indian|\n",
      "|Cauliflower and T...|Pressed tofu cube...|indian|\n",
      "|Channa Masala (Ch...|This fantastic In...|indian|\n",
      "|Bengali Chicken C...|Thy this deliciou...|indian|\n",
      "|  Indian Sweet Bread|A crisp and sweet...|indian|\n",
      "| Rosy's Palak Paneer|An Indian friend ...|indian|\n",
      "|Roti Bread from I...|This version of t...|indian|\n",
      "|Indian Vegetable ...|Basmati rice enha...|indian|\n",
      "+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine 3 dataset into one\n",
    "\n",
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def unionAll(dfs):\n",
    "    return reduce(DataFrame.unionAll, dfs)\n",
    "\n",
    "dfs = [indian, italian, mexican]\n",
    "recipe = unionAll(dfs)\n",
    "recipe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert it to RDD\n",
    "recipe_rdd = recipe.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Title='Indian Peanut Stew', Description='This is an easy, authentic dish from South Asia that appeals to a wide range of tastes. The…', label='indian'),\n",
       " Row(Title='Roomali Roti', Description='There is no leavening in this simple, tender Indian flatbread of bread flour, oil, salt and…', label='indian'),\n",
       " Row(Title='Spicy Sweet Potato Salad', Description=\"It's important to use good mayonnaise in this recipe, and to let the cooked potatoes chill…\", label='indian'),\n",
       " Row(Title='Chicken Saag', Description='The classic Indian chicken and spinach dish gets richness from sour cream.', label='indian'),\n",
       " Row(Title='Paleo Slow Cooker Pork Loin', Description='Boneless pork loin slowly cooks in a curried fruit sauce until tender and delicious.', label='indian')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### note\n",
    "Not sure if we can split data as what I did in pandas, if not, we could get training, test dataset (csv) prepared before loading them in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preperation\n",
    "### Data Cleaning\n",
    "\n",
    "We can know that we have 1500 recipes for this project. By looking at the few columns we noticed that there are many useless information contained in our dataset, such as numbers, stop words and punctuation. And alse it mixed the uppercase and the lowercase. For this part, we will remove those noisy information and transfermed all letters into lowercase to get a cleaned dataset for labeling function.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Title='indian peanut stew', Description='this is an easy, authentic dish from south asia that appeals to a wide range of tastes. the…', label='indian'),\n",
       " Row(Title='roomali roti', Description='there is no leavening in this simple, tender indian flatbread of bread flour, oil, salt and…', label='indian'),\n",
       " Row(Title='spicy sweet potato salad', Description=\"it's important to use good mayonnaise in this recipe, and to let the cooked potatoes chill…\", label='indian'),\n",
       " Row(Title='chicken saag', Description='the classic indian chicken and spinach dish gets richness from sour cream.', label='indian'),\n",
       " Row(Title='paleo slow cooker pork loin', Description='boneless pork loin slowly cooks in a curried fruit sauce until tender and delicious.', label='indian')]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the RDD Lowercase\n",
    "\n",
    "recipe_1 = recipe.select(*[lower(col(col_name)).name(col_name) for col_name in recipe.columns])\n",
    "\n",
    "recipe_rdd_1 = recipe_1.rdd\n",
    "\n",
    "# Displaying new RDD\n",
    "\n",
    "recipe_rdd_1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Description_1: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- Label: string (nullable = false)\n",
      "\n",
      "+--------------------+--------------------+------+\n",
      "|               Title|       Description_1| Label|\n",
      "+--------------------+--------------------+------+\n",
      "|  Indian Peanut Stew|[this, is, an, ea...|indian|\n",
      "|        Roomali Roti|[there, is, no, l...|indian|\n",
      "|Spicy Sweet Potat...|[it's, important,...|indian|\n",
      "|        Chicken Saag|[the, classic, in...|indian|\n",
      "|Paleo Slow Cooker...|[boneless, pork, ...|indian|\n",
      "|Bombay Chicken an...|[chicken, parts, ...|indian|\n",
      "|Indian Carrots, P...|[potatoes,, peas,...|indian|\n",
      "|Wendy's Indian Bu...|[this, recipe, re...|indian|\n",
      "|    Indian Chickpeas|[garbanzo, beans,...|indian|\n",
      "|Dal Makhani (Indi...|[these, richly, s...|indian|\n",
      "+--------------------+--------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"Description\", outputCol=\"Description_1\")\n",
    "recipe_rdd_2 = tokenizer.transform(recipe).select('Title', \"Description_1\", 'Label')\n",
    "\n",
    "recipe_rdd_2.printSchema()\n",
    "recipe_rdd_2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "# Define a list of stop words or use default list\n",
    "remover = StopWordsRemover()\n",
    "stopwords = remover.getStopWords() \n",
    "\n",
    "# Display default list\n",
    "stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Description_2: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- Label: string (nullable = false)\n",
      "\n",
      "+--------------------+--------------------+------+\n",
      "|               Title|       Description_2| Label|\n",
      "+--------------------+--------------------+------+\n",
      "|  Indian Peanut Stew|[easy,, authentic...|indian|\n",
      "|        Roomali Roti|[leavening, simpl...|indian|\n",
      "|Spicy Sweet Potat...|[important, use, ...|indian|\n",
      "|        Chicken Saag|[classic, indian,...|indian|\n",
      "|Paleo Slow Cooker...|[boneless, pork, ...|indian|\n",
      "|Bombay Chicken an...|[chicken, parts, ...|indian|\n",
      "|Indian Carrots, P...|[potatoes,, peas,...|indian|\n",
      "|Wendy's Indian Bu...|[recipe, resemble...|indian|\n",
      "|    Indian Chickpeas|[garbanzo, beans,...|indian|\n",
      "|Dal Makhani (Indi...|[richly, spiced, ...|indian|\n",
      "|               Raita|[chopped, tomatoe...|indian|\n",
      "|Yogurt-Marinated ...|[yogurt-based, ma...|indian|\n",
      "|Indian-Spiced Roa...|[spicy, roasted, ...|indian|\n",
      "|Cauliflower and T...|[pressed, tofu, c...|indian|\n",
      "|Channa Masala (Ch...|[fantastic, india...|indian|\n",
      "|Bengali Chicken C...|[thy, delicious, ...|indian|\n",
      "|  Indian Sweet Bread|[crisp, sweet, fl...|indian|\n",
      "| Rosy's Palak Paneer|[indian, friend, ...|indian|\n",
      "|Roti Bread from I...|[version, delicat...|indian|\n",
      "|Indian Vegetable ...|[basmati, rice, e...|indian|\n",
      "+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify input/output columns\n",
    "remover.setInputCol(\"Description_1\")\n",
    "remover.setOutputCol(\"Description_2\")\n",
    "\n",
    "# Transform existing dataframe with the StopWordsRemover\n",
    "recipe_rdd_3 = remover.transform(recipe_rdd_2).select('Title', \"Description_2\", 'Label')\n",
    "\n",
    "# Display\n",
    "recipe_rdd_3.printSchema()\n",
    "recipe_rdd_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing numbers\n",
    "\n",
    "from pyspark.sql.functions import when,udf\n",
    "from pyspark.sql.types import BooleanType\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.sql.types import StructType\n",
    "\n",
    "def is_digit(value):\n",
    "    if value:\n",
    "        return value.isdigit()\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "is_digit_udf = udf(is_digit, BooleanType())\n",
    "\n",
    "filter_length_udf = udf(lambda row: [x for x in row if not is_digit(x)], ArrayType(StringType()))\n",
    "recipe_rdd_4 = recipe_rdd_3.withColumn('Description_2', filter_length_udf(col('Description_2')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Title='Indian Peanut Stew', Description_2=['easy,', 'authentic', 'dish', 'south', 'asia', 'appeals', 'wide', 'range', 'tastes.', 'the…'], Label='indian'),\n",
       " Row(Title='Roomali Roti', Description_2=['leavening', 'simple,', 'tender', 'indian', 'flatbread', 'bread', 'flour,', 'oil,', 'salt', 'and…'], Label='indian'),\n",
       " Row(Title='Spicy Sweet Potato Salad', Description_2=['important', 'use', 'good', 'mayonnaise', 'recipe,', 'let', 'cooked', 'potatoes', 'chill…'], Label='indian'),\n",
       " Row(Title='Chicken Saag', Description_2=['classic', 'indian', 'chicken', 'spinach', 'dish', 'gets', 'richness', 'sour', 'cream.'], Label='indian'),\n",
       " Row(Title='Paleo Slow Cooker Pork Loin', Description_2=['boneless', 'pork', 'loin', 'slowly', 'cooks', 'curried', 'fruit', 'sauce', 'tender', 'delicious.'], Label='indian')]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_rdd_4 = recipe_rdd_4.rdd\n",
    "recipe_rdd_4.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
