{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "snorkel_lf.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uceikow/DataEngineeringGroupAO/blob/master/snorkel_lf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL0ih9fRhPEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install snorkel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1h9pOtvj_51",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "cea01d61-03be-4bd0-e4b2-9638c56cfafc"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFG3hE1Mm7HA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "61826594-4676-499f-8610-1f4012377cc6"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TZSIWKjkYiG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "3882c569-cae4-4ae2-cb4f-9d179f72f7a8"
      },
      "source": [
        "# Install spark-related dependencies\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# !wget -q http://www-eu.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "# !tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "# Set up required environment variables\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/drive/My Drive/spark-2.4.5-bin-hadoop2.7\"\n",
        "!pip install pyspark\n",
        "!pip install altair"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (2.4.5)\n",
            "Requirement already satisfied: py4j==0.10.7 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.7)\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (2.4.5)\n",
            "Requirement already satisfied: py4j==0.10.7 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.7)\n",
            "Requirement already satisfied: altair in /usr/local/lib/python3.6/dist-packages (4.0.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from altair) (2.11.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from altair) (0.25.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from altair) (0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from altair) (1.17.5)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from altair) (2.6.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.6/dist-packages (from altair) (0.10.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->altair) (1.1.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->altair) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->altair) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->altair) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzMzZ5c8hPEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install spacy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcrYo7xyhPEp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "a176c5e6-0d61-4668-826a-c9e011f13ddc"
      },
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9ntcGwAhPE5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2b4b9319-bf87-447c-b0b6-4e00d5df64e9"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "import pyspark\n",
        "# get a spark context\n",
        "sc = pyspark.SparkContext.getOrCreate()\n",
        "print(sc)\n",
        "\n",
        "# get the context\n",
        "sqlContext = pyspark.sql.SparkSession.builder.getOrCreate()\n",
        "print(sqlContext)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<SparkContext master=local[*] appName=pyspark-shell>\n",
            "<pyspark.sql.session.SparkSession object at 0x7faa1bd5beb8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8NMX7sJBFWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display full output rather than just the last line of output\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVHdxlF4hPFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load dataset\n",
        "import pandas as pd\n",
        "\n",
        "indian = pd.read_csv(\"/content/data_indian.csv\")\n",
        "indian['label'] = 'indian'\n",
        "italian = pd.read_csv(\"/content/data_italian.csv\")\n",
        "italian['label'] = 'italian'\n",
        "mexican = pd.read_csv(\"/content/data_mexican.csv\")\n",
        "mexican['label'] = 'mexican'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYDYOIHqqi3z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "d20da84c-cb5f-48e9-a199-384b58180452"
      },
      "source": [
        "# Concat them into one dataset\n",
        "recipe = pd.concat([indian, italian, mexican],ignore_index = True)\n",
        "recipe"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Indian Peanut Stew</td>\n",
              "      <td>This is an easy, authentic dish from South Asi...</td>\n",
              "      <td>indian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Roomali Roti</td>\n",
              "      <td>There is no leavening in this simple, tender I...</td>\n",
              "      <td>indian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Spicy Sweet Potato Salad</td>\n",
              "      <td>It's important to use good mayonnaise in this ...</td>\n",
              "      <td>indian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Chicken Saag</td>\n",
              "      <td>The classic Indian chicken and spinach dish ge...</td>\n",
              "      <td>indian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Paleo Slow Cooker Pork Loin</td>\n",
              "      <td>Boneless pork loin slowly cooks in a curried f...</td>\n",
              "      <td>indian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>Taco Stew</td>\n",
              "      <td>Ground beef and onions sauteed with a packet o...</td>\n",
              "      <td>mexican</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>Chicken Tortilla Soup in the Slow Cooker</td>\n",
              "      <td>Everyone loves using their slow cooker to make...</td>\n",
              "      <td>mexican</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>Bountiful Garden Zucchini Enchiladas</td>\n",
              "      <td>Fresh zucchini and Monterey Jack cheese filled...</td>\n",
              "      <td>mexican</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>Bean and Honey Burrito Casserole</td>\n",
              "      <td>Here's a great way to feed burritos to a crowd...</td>\n",
              "      <td>mexican</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>Green Chile Chicken Stew</td>\n",
              "      <td>This stew will keep you warm and cozy on those...</td>\n",
              "      <td>mexican</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Title  ...    label\n",
              "0                           Indian Peanut Stew  ...   indian\n",
              "1                                 Roomali Roti  ...   indian\n",
              "2                     Spicy Sweet Potato Salad  ...   indian\n",
              "3                                 Chicken Saag  ...   indian\n",
              "4                  Paleo Slow Cooker Pork Loin  ...   indian\n",
              "...                                        ...  ...      ...\n",
              "1495                                 Taco Stew  ...  mexican\n",
              "1496  Chicken Tortilla Soup in the Slow Cooker  ...  mexican\n",
              "1497      Bountiful Garden Zucchini Enchiladas  ...  mexican\n",
              "1498          Bean and Honey Burrito Casserole  ...  mexican\n",
              "1499                  Green Chile Chicken Stew  ...  mexican\n",
              "\n",
              "[1500 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdbski8thPFQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "83732d81-a32c-4f55-d41c-6d54f8765fcd"
      },
      "source": [
        "! pip install nltk"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5B5GRAyfhPFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk import sent_tokenize, word_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Byvg_0k7hPFU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "265e81ea-f562-4559-cf93-488213f3540b"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdZMV8XFyXfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsgxdYe9p-TS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean the dataset\n",
        "# Lowercase\n",
        "recipe = recipe.apply(lambda row: row.str.lower())\n",
        "\n",
        "# Remove digits\n",
        "recipe['Title'] = recipe.apply((lambda row: ''.join([i for i in row['Title'] if not i.isdigit()])),axis = 1)\n",
        "recipe['Description'] = recipe.apply((lambda row: ''.join([i for i in row['Description'] if not i.isdigit()])),axis = 1)\n",
        "\n",
        "# Remove punctuations\n",
        "recipe['Title'] = recipe.apply((lambda row: ''.join([i for i in row['Title'] if i not in string.punctuation])),axis=1)\n",
        "recipe['Description'] = recipe.apply((lambda row: ''.join([i for i in row['Description'] if i not in string.punctuation])),axis=1)\n",
        "\n",
        "# Remove Stopwords\n",
        "stop = stopwords.words('english')\n",
        "recipe['Title'] = recipe['Title'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "recipe['Description'] = recipe['Description'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPeGEU8Z5dIZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "160cab6b-5b0c-4022-a98e-74d282eca748"
      },
      "source": [
        "recipe.head()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>indian peanut stew</td>\n",
              "      <td>easy authentic dish south asia appeals wide ra...</td>\n",
              "      <td>indian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>roomali roti</td>\n",
              "      <td>leavening simple tender indian flatbread bread...</td>\n",
              "      <td>indian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spicy sweet potato salad</td>\n",
              "      <td>important use good mayonnaise recipe let cooke...</td>\n",
              "      <td>indian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>chicken saag</td>\n",
              "      <td>classic indian chicken spinach dish gets richn...</td>\n",
              "      <td>indian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>paleo slow cooker pork loin</td>\n",
              "      <td>boneless pork loin slowly cooks curried fruit ...</td>\n",
              "      <td>indian</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Title  ...   label\n",
              "0           indian peanut stew  ...  indian\n",
              "1                 roomali roti  ...  indian\n",
              "2     spicy sweet potato salad  ...  indian\n",
              "3                 chicken saag  ...  indian\n",
              "4  paleo slow cooker pork loin  ...  indian\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOFD7g02CwKl",
        "colab_type": "text"
      },
      "source": [
        "Before splitting the dataset and writing labelling function,  we might want to first get an idea of how our targetting labels look like. This gives us some basic information of how to start building the labelling function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgzIrjKY9S9x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "outputId": "53f64bd4-685d-4e7a-fb91-775fb02ef590"
      },
      "source": [
        "# Patterns from indian food\n",
        "\n",
        "# Filter out indian food\n",
        "recipe_ind = recipe[recipe['label'] == 'indian']\n",
        "\n",
        "# Word frequency in 'Title'\n",
        "top_N = 15\n",
        "titles = recipe_ind.Title.str.cat(sep=' ')\n",
        "words_in_title = nltk.tokenize.word_tokenize(titles)\n",
        "word_dist_title = nltk.FreqDist(words_in_title)\n",
        "print('All frequencies:')\n",
        "print('=' * 60)\n",
        "t_freq = pd.DataFrame(word_dist_title.most_common(top_N),\n",
        "                    columns=['Word_title', 'Frequency'])\n",
        "print(t_freq)\n",
        "print('=' * 60)\n",
        "\n",
        "# Word frequency in 'Description'\n",
        "des = recipe_ind.Description.str.cat(sep=' ')\n",
        "words_in_des = nltk.tokenize.word_tokenize(des)\n",
        "word_dist_des = nltk.FreqDist(words_in_des)\n",
        "print('All frequencies:')\n",
        "print('=' * 60)\n",
        "d_freq = pd.DataFrame(word_dist_des.most_common(top_N),\n",
        "                    columns=['Word_description', 'Frequency'])\n",
        "print(d_freq)\n",
        "print('=' * 60)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All frequencies:\n",
            "============================================================\n",
            "   Word_title  Frequency\n",
            "0     chicken         92\n",
            "1       curry         82\n",
            "2      indian         72\n",
            "3      masala         30\n",
            "4        rice         28\n",
            "5       spicy         25\n",
            "6     curried         21\n",
            "7      paneer         20\n",
            "8     chutney         20\n",
            "9        soup         20\n",
            "10      salad         19\n",
            "11       easy         19\n",
            "12       lamb         17\n",
            "13     tomato         17\n",
            "14     potato         16\n",
            "============================================================\n",
            "All frequencies:\n",
            "============================================================\n",
            "   Word_description  Frequency\n",
            "0            indian        119\n",
            "1             curry        101\n",
            "2              dish         83\n",
            "3           chicken         80\n",
            "4            recipe         61\n",
            "5              rice         53\n",
            "6             spicy         51\n",
            "7            spices         50\n",
            "8              made         48\n",
            "9             sauce         44\n",
            "10             easy         41\n",
            "11         simmered         39\n",
            "12           yogurt         36\n",
            "13         potatoes         35\n",
            "14             make         35\n",
            "============================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EEimMn1BXzs",
        "colab_type": "text"
      },
      "source": [
        "From the frequency list we could see that some of the words, such as indian, curry, chicken, spicy, spiced, masala, etc,  are frequently showed up in indian recipe. We can include these words into labelling function.\n",
        "\n",
        "Inspection is ongoing. Feel free to explore the indian recipe to get useful information to inform the labelling functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXbdMtOGEFPi",
        "colab_type": "text"
      },
      "source": [
        "As being discussed in group meeting, we split the dataset into training, validation, development and test datasets.\n",
        "\n",
        "If we do multi-labelling, we need to make sure that all datasets above contains same proportion of the 3 recipes. I decided to have 30% labelled data, in which 10% for dev set, 10% for validation set, and the remaining 10% for test set. We left 70% data to training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Agcde9nWCooH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the dataset\n",
        "# Use ShuffleStratifiedSplit to ensure same proportion of each dataset\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "sss = StratifiedShuffleSplit(n_splits=3, test_size=0.3, random_state=0)\n",
        "\n",
        "# Get different labelled data\n",
        "ind = recipe[recipe['label'] == 'indian']\n",
        "ind.reset_index(drop=True,inplace=True)\n",
        "ita = recipe[recipe['label'] == 'italian']\n",
        "ita.reset_index(drop=True,inplace=True)\n",
        "mex = recipe[recipe['label'] == 'mexican']\n",
        "mex.reset_index(drop=True,inplace=True)\n",
        "\n",
        "# Split function (leave 70% for training)\n",
        "def shuffle_split(df,sss):\n",
        "  X = df[['Title','Description']]\n",
        "  y = df['label']\n",
        "  for train_index, test_index in sss.split(X, y):\n",
        "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "ind_train, ind_test, ind_train, ind_test = shuffle_split(ind,sss)\n",
        "ita_train, ita_test, ita_train, ita_test = shuffle_split(ita,sss)\n",
        "mex_train, mex_test, mex_train, mex_test = shuffle_split(mex,sss)\n",
        "\n",
        "# From randomly sampled test set get dev set and validation set.\n",
        "ind_val, ind_dev = ind_test[:50], ind_test[50:100]\n",
        "ita_val, ita_dev = ita_test[:50], ita_test[50:100]\n",
        "mex_val, mex_dev = mex_test[:50], mex_test[50:100]\n",
        "ind_test, ita_test, mex_test = ind_test[100:150], ita_test[100:150], mex_test[100:150]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OxgR17ORUlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}